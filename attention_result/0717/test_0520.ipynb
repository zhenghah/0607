{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test as Haha\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "# chembl 推测子结构\n",
    "getdata = Haha.BasicData(which_data=None)\n",
    "smiles_list = getdata.readSmiles(filelist=['webScrapping/chembl_smi.txt'])\n",
    "\n",
    "print(len(smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odlist_4 = [\n",
    "#     'sweet', 'sour', 'fruity', 'musky', 'chemical'\n",
    "# ]\n",
    "odlist_4 = [\n",
    "    'sweet', 'fruity', \n",
    "]\n",
    "\n",
    "getdata = Haha.BasicData(which_data='Paper')\n",
    "getdata.which_data = 'keller'\n",
    "getdata.readOD(50, od_selected=odlist_4, filelist=['keller.txt'])\n",
    "smiles_list = getdata.readSmiles(filelist=['keller.txt'])\n",
    "print(len(smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all type odor descriptors = 970\n",
      "appear times >= 50 odor descriptors have 64\n",
      "they are\n",
      "['fruity', 'sweet', 'green', 'floral', 'woody', 'herbaceous', 'fatty', 'fresh', 'waxy', 'rose', 'spicy', 'citrus', 'earthy', 'tropical', 'oily', 'nutty', 'roasted', 'sulfurous', 'balsam', 'apple', 'dry', 'powdery', 'phenolic', 'vegetable', 'pineapple', 'bland', 'aldehydic', 'musty', 'creamy', 'minty', 'meaty', 'metallic', 'honey', 'onion', 'berry', 'balsamic', 'jasmin', 'spice', 'pungent', 'animal', 'musk', 'caramel', 'burnt', 'camphor', 'coconut', 'coffee', 'mushroom', 'garlic', 'natural', 'violet', 'peach', 'tobacco', 'pine', 'geranium', 'vanilla', 'cocoa', 'sulfury', 'nut', 'cooked', 'lily', 'hyacinth', 'apricot', 'cherry', 'almond']\n",
      "final od_times with all samples: {'fruity': 1209, 'sweet': 1059, 'green': 1034, 'floral': 851, 'woody': 598, 'herbaceous': 532, 'fatty': 404}\n",
      "3708\n",
      "879\n",
      "4587\n"
     ]
    }
   ],
   "source": [
    "odlist_4 = [\n",
    "    'fruity', 'sweet', 'green', 'floral', 'woody', 'herbaceous', 'fatty'\n",
    "]\n",
    "# odlist_4 = [\n",
    "#     'sweet', 'fruity'\n",
    "# ]\n",
    "\n",
    "getdata = Haha.BasicData(which_data='Paper')# 最终用这个\n",
    "# getdata = Haha.BasicData(which_data='GoodScent')\n",
    "getdata.readOD(50, od_selected=odlist_4)\n",
    "smiles_list = getdata.readSmiles()\n",
    "print(len(smiles_list))\n",
    "\n",
    "getdata.which_data = 'odorless'\n",
    "# smiles_list_odorless = getdata.readSmiles(filelist=['smilesodFromPaper_odorless.txt'])\n",
    "smiles_list_odorless = getdata.readSmiles(filelist=['webScrapping/my_odoless.txt']) # 最终用这个\n",
    "# smiles_list_odorless = getdata.readSmiles(filelist=['webScrapping/tgsc_odorless.txt'])\n",
    "print(len(smiles_list_odorless))\n",
    "\n",
    "smiles_list.extend(smiles_list_odorless)\n",
    "print(len(smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odlist_4 = [\n",
    "#     'fruity', 'sweet', 'green', 'floral', 'woody', 'herbaceous', 'fatty'\n",
    "# ]\n",
    "odlist_4 = [\n",
    "    'sweet', #'fruity'\n",
    "]\n",
    "\n",
    "getdata = Haha.BasicData(which_data='keller')\n",
    "getdata.readOD(50, od_selected=odlist_4, filelist=['summary_no_keller.txt'])\n",
    "smiles_list = getdata.readSmiles(filelist=['summary_no_keller.txt'])\n",
    "print(len(smiles_list))\n",
    "\n",
    "getdata.which_data = 'odorless'\n",
    "# smiles_list_odorless = getdata.readSmiles(filelist=['smilesodFromPaper_odorless.txt'])\n",
    "smiles_list_odorless = getdata.readSmiles(filelist=['webScrapping/my_odoless.txt'])\n",
    "print(len(smiles_list_odorless))\n",
    "\n",
    "smiles_list.extend(smiles_list_odorless)\n",
    "print(len(smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer2OD_tada\n",
      "transformer2od\n",
      "54 mol cannot compute distance, they are: [1992, 1994, 1999, 2005, 2012, 2016, 2018, 2024, 2513, 2565, 3057, 3068, 3260, 3261, 3270, 3289, 3329, 3553, 3554, 3650, 3833, 3871, 3883, 3889, 3938, 4179, 4189, 4235, 4335, 4336, 4337, 4409, 4442, 4469, 4475, 4491, 4502, 4522, 4523, 4524, 4526, 4539, 4543, 4560, 4561, 4565, 4568, 4569, 4574, 4578, 4580, 4582, 4583, 4586]\n",
      "num_sample : 4533\n",
      "mask_mat: (4533, 1, 1, 60)\n",
      "mol_atom_feat.shape: (4533, 60, 71)\n",
      "distance value type is: exp\n",
      "all_adj.shape = : (4533, 60, 60)\n",
      "all_dist.shape = : (4533, 60, 60)\n",
      "od_shuffled.shape =  (4533, 7)\n",
      "positive sample distribution in test set:\n",
      "{'fruity': 201.0, 'sweet': 144.0, 'green': 150.0, 'floral': 125.0, 'woody': 89.0, 'herbaceous': 93.0, 'fatty': 77.0}\n",
      "positive sample distribution in test set:\n",
      "{'fruity': 1007.0, 'sweet': 913.0, 'green': 880.0, 'floral': 726.0, 'woody': 504.0, 'herbaceous': 437.0, 'fatty': 324.0}\n"
     ]
    }
   ],
   "source": [
    "test = Haha.Transformer2OD_tada()\n",
    "# test.train_test = (4000,1)\n",
    "test.molData_atomicF(smiles_list, dist_value='exp', atomH=False, failed_mol=None, rseed=1)\n",
    "test.odData(getdata.od_mat_ori, getdata.od_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "hpara = {\n",
    "            'num_heads': 2,\n",
    "            'single_attn_dim': 30,\n",
    "            'num_encoderLayer': 2,\n",
    "            'num_decoderLayer': 1, \n",
    "            'learning_rate': 0.00002, \n",
    "            'temperature': 0.7\n",
    "        }\n",
    "\n",
    "record_dir='/tf/haha/code/logs/0525/0'\n",
    "\n",
    "weight_path = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.foldTrain(hpara, 5, record_dir, save_path='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "hparams_dict = {\n",
    "            'num_heads': [4],\n",
    "            'single_attn_dim': [30],\n",
    "            'num_encoderLayer': [1, 2],\n",
    "            'num_decoderLayer': [1],\n",
    "            'learning_rate': [0.00002],\n",
    "            'temperature': [0.7]\n",
    "        }\n",
    "test.HPset(hparams_dict)\n",
    "\n",
    "record_hp = '/tf/haha/tensorboard_logs/trans/0525/test/'\n",
    "test.hpTableCreat(record_hp)\n",
    "\n",
    "test.modelTrain_hp1(run_count_begin=0, max_epochs=10, save_threshold=None, save_path=None, foldfile='/tf/haha/tensorboard_logs/trans/0525/test/record.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "hpara = {\n",
    "            'num_heads': 6,\n",
    "            'single_attn_dim': 30,\n",
    "            'num_encoderLayer': 5,\n",
    "            'num_decoderLayer': 1, \n",
    "            'learning_rate': 0.00002, \n",
    "            'temperature': 0.7\n",
    "        }\n",
    "\n",
    "# record_dir='/tf/haha/code/logs/0630/tgsc_only'\n",
    "\n",
    "# weight_path = '/tf/haha/save_weight/0630/tgsc_only/'\n",
    "\n",
    "# record_dir='/tf/haha/code/logs/0713/no-contrastive'\n",
    "\n",
    "# weight_path = '/tf/haha/save_weight/0713/no-contrastive/'\n",
    "\n",
    "# record_dir='/tf/haha/code/logs/0719/od-6_30_52'\n",
    "\n",
    "# weight_path = '/tf/haha/save_weight/0719/od-6_30_52/'\n",
    "\n",
    "record_dir='/tf/haha/code/logs/0719/od-6_30_51'\n",
    "\n",
    "weight_path = '/tf/haha/save_weight/0719/od-6_30_51/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.test_input = test1.test_input\n",
    "test.od_test = test1.od_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.od_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.modelTrain_SAM(hpara, epochs=200, batch_size=32, record_dir=record_dir, save_threshold=0.50, \n",
    "                    save_path=weight_path, normal_init=False, rho=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/haha/code/logs/0719/od-6_30_51\n",
      "modelBuild2-temperature 0.700000\n",
      "(3775, 1, 1)\n",
      "(3775, 60, 71)\n",
      "(3775, 60, 60)\n",
      "(3775, 60, 60)\n",
      "(3775, 1, 1, 60)\n",
      "(3775, 7)\n",
      "0 WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (31, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (31, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (31, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (31, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (31, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 7) for input KerasTensor(type_spec=TensorSpec(shape=(32, 7), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (31, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (22, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (22, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (22, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (22, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (22, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 7) for input KerasTensor(type_spec=TensorSpec(shape=(32, 7), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (22, 7).\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 weight保存开始：Wed Jul 20 23:52:19 2022 weight保存完成 Wed Jul 20 23:52:19 2022\n",
      "18 weight保存开始：Wed Jul 20 23:52:24 2022 weight保存完成 Wed Jul 20 23:52:24 2022\n",
      "19 20 21 22 23 weight保存开始：Wed Jul 20 23:52:49 2022 weight保存完成 Wed Jul 20 23:52:49 2022\n",
      "24 25 26 27 weight保存开始：Wed Jul 20 23:53:08 2022 weight保存完成 Wed Jul 20 23:53:08 2022\n",
      "28 29 30 31 32 33 34 35 weight保存开始：Wed Jul 20 23:53:47 2022 weight保存完成 Wed Jul 20 23:53:47 2022\n",
      "36 37 38 weight保存开始：Wed Jul 20 23:54:02 2022 weight保存完成 Wed Jul 20 23:54:02 2022\n",
      "39 40 41 weight保存开始：Wed Jul 20 23:54:17 2022 weight保存完成 Wed Jul 20 23:54:17 2022\n",
      "42 43 44 45 46 weight保存开始：Wed Jul 20 23:54:41 2022 weight保存完成 Wed Jul 20 23:54:41 2022\n",
      "47 weight保存开始：Wed Jul 20 23:54:46 2022 weight保存完成 Wed Jul 20 23:54:46 2022\n",
      "48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 weight保存开始：Wed Jul 20 23:56:43 2022 weight保存完成 Wed Jul 20 23:56:43 2022\n",
      "72 weight保存开始：Wed Jul 20 23:56:48 2022 weight保存完成 Wed Jul 20 23:56:48 2022\n",
      "73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 weight保存开始：Wed Jul 20 23:58:20 2022 weight保存完成 Wed Jul 20 23:58:20 2022\n",
      "92 93 94 95 96 97 98 99 {'avg': 0.5498456263935532, 'avg_pcs': 0.47662336911473957, 'avg_rc': 0.657230807202203, 'fruity': 0.6854460209673107, 'sweet': 0.514285708071261, 'green': 0.5187032500144907, 'floral': 0.6060606184577154, 'woody': 0.6161616157571971, 'herbaceous': 0.4055299454805802, 'fatty': 0.5027322260063166}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x7f806823a910>,\n",
       " {'avg': 0.5498456263935532,\n",
       "  'avg_pcs': 0.47662336911473957,\n",
       "  'avg_rc': 0.657230807202203,\n",
       "  'fruity': 0.6854460209673107,\n",
       "  'sweet': 0.514285708071261,\n",
       "  'green': 0.5187032500144907,\n",
       "  'floral': 0.6060606184577154,\n",
       "  'woody': 0.6161616157571971,\n",
       "  'herbaceous': 0.4055299454805802,\n",
       "  'fatty': 0.5027322260063166})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.modelTrain2(hpara, epochs=100, batch_size=32, record_dir=record_dir, save_threshold=0.5, save_path=weight_path, normal_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'MAT'\n",
    "hpara = {\n",
    "            'num_heads': 6,\n",
    "            'single_attn_dim': 30,\n",
    "            'num_encoderLayer': 2,\n",
    "            'num_decoderLayer': 3, \n",
    "            'learning_rate': 0.00002, \n",
    "            'temperature': 0.7\n",
    "        }\n",
    "\n",
    "record_dir='/tf/haha/code/logs/0527/MAT'\n",
    "\n",
    "weight_path = '/tf/haha/save_weight/0527/MAT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.modelTrain2(hpara, epochs=100, batch_size=32, record_dir=record_dir, save_threshold=0.51, save_path=weight_path, normal_init=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "hpara = {\n",
    "            'num_heads': 6,\n",
    "            'single_attn_dim': 30,\n",
    "            'num_encoderLayer': 2,\n",
    "            'num_decoderLayer': 3, \n",
    "            'learning_rate': 0.00002, \n",
    "            'temperature': 0.7\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_5 = []\n",
    "good_6 = []\n",
    "for i in range(10, 100):\n",
    "    record_dir='/tf/haha/code/logs/0527/repeat1/%d' % i\n",
    "    weight_path = '/tf/haha/save_weight/0527/repeat1/%d/' % i\n",
    "    _, f_dict = test.modelTrain2(hpara, epochs=80, batch_size=32, record_dir=record_dir, save_threshold=0.52, save_path=weight_path, normal_init=False)\n",
    "    if f_dict['avg'] >= 0.55:\n",
    "        good_5.append(i)\n",
    "        if f_dict['avg'] >= 0.56:\n",
    "            good_6.append(i)\n",
    "print(good_5)\n",
    "print(good_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpara = {\n",
    "            'num_heads': 6,\n",
    "            'single_attn_dim': 30,\n",
    "            'num_encoderLayer': 3,\n",
    "            'num_decoderLayer': 2, \n",
    "            'learning_rate': 0.0002, \n",
    "            'temperature': 0.7\n",
    "        }\n",
    "\n",
    "record_dir='/tf/haha/code/logs/0527/econly'\n",
    "\n",
    "weight_path = '/tf/haha/save_weight/0527/econly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.modelTrain2(hpara, epochs=250, batch_size=32, record_dir=record_dir, save_threshold=0.45, save_path=weight_path, normal_init=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "hparams_dict = {\n",
    "            'num_heads': [4, 6],\n",
    "            'single_attn_dim': [30],\n",
    "            'num_encoderLayer': [2, 3],\n",
    "            'num_decoderLayer': [3, 4, 5],\n",
    "            'learning_rate': [0.00002],\n",
    "            'temperature': [0.7]\n",
    "        }\n",
    "test.HPset(hparams_dict)\n",
    "\n",
    "record_hp = '/tf/haha/tensorboard_logs/trans/0520/keller5/'\n",
    "test.hpTableCreat(record_hp)\n",
    "\n",
    "test.modelTrain_hp1(run_count_begin=0, max_epochs=150, save_threshold=0.53, save_path='/tf/haha/save_weight/0520/keller5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "hparams_dict = {\n",
    "            'num_heads': [4, 6],\n",
    "            'single_attn_dim': [20, 30],\n",
    "            'num_encoderLayer': [2, 3],\n",
    "            'num_decoderLayer': [2, 3],\n",
    "            'learning_rate': [0.00002],\n",
    "            'temperature': [0.7]\n",
    "        }\n",
    "test.HPset(hparams_dict)\n",
    "\n",
    "record_hp = '/tf/haha/tensorboard_logs/trans/0520/keller5_1/'\n",
    "test.hpTableCreat(record_hp)\n",
    "\n",
    "test.modelTrain_hp1(run_count_begin=0, max_epochs=300, save_threshold=0.53, save_path='/tf/haha/save_weight/0520/keller5_1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torsion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_attnTorsion\n",
      "Transformer2OD_tada\n",
      "transformer2od\n",
      "54 mol cannot compute distance, they are: [1992, 1994, 1999, 2005, 2012, 2016, 2018, 2024, 2513, 2565, 3057, 3068, 3260, 3261, 3270, 3289, 3329, 3553, 3554, 3650, 3833, 3871, 3883, 3889, 3938, 4179, 4189, 4235, 4335, 4336, 4337, 4409, 4442, 4469, 4475, 4491, 4502, 4522, 4523, 4524, 4526, 4539, 4543, 4560, 4561, 4565, 4568, 4569, 4574, 4578, 4580, 4582, 4583, 4586]\n",
      "num_sample : 4533\n",
      "mask_mat: (4533, 1, 1, 60)\n",
      "mol_atom_feat.shape: (4533, 60, 71)\n",
      "distance value type is: exp\n",
      "all_adj.shape = : (4533, 60, 60)\n",
      "all_dist.shape = : (4533, 60, 60)\n",
      "begin to comput angle and dehidral angle\n",
      "all_pair.shape: (4533, 60, 60, 4)\n",
      "od_shuffled.shape =  (4533, 7)\n",
      "positive sample distribution in test set:\n",
      "{'fruity': 201.0, 'sweet': 144.0, 'green': 150.0, 'floral': 125.0, 'woody': 89.0, 'herbaceous': 93.0, 'fatty': 77.0}\n",
      "positive sample distribution in test set:\n",
      "{'fruity': 1007.0, 'sweet': 913.0, 'green': 880.0, 'floral': 726.0, 'woody': 504.0, 'herbaceous': 437.0, 'fatty': 324.0}\n"
     ]
    }
   ],
   "source": [
    "test = Haha.Transformer_attnTorsion()\n",
    "# test.train_test = (4000,1)\n",
    "test.molData_atomicF(smiles_list, dist_value='exp', atomH=False, failed_mol=None, rseed=1)\n",
    "test.odData(getdata.od_mat_ori, getdata.od_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpara = {\n",
    "            'num_heads': 6,\n",
    "            'single_attn_dim': 30,\n",
    "            'num_encoderLayer': 2,\n",
    "            'num_decoderLayer': 3, \n",
    "            'learning_rate': 0.00002, \n",
    "            'temperature': 0.7\n",
    "        }\n",
    "\n",
    "record_dir='/tf/haha/code/logs/0624/torsion'\n",
    "\n",
    "weight_path = '/tf/haha/save_weight/0624/torsion/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/haha/code/logs/0624/torsion\n",
      "modelBuild2-temperature 0.700000\n",
      "(3775, 1, 1)\n",
      "(3775, 60, 71)\n",
      "(3775, 60, 60)\n",
      "(3775, 60, 60, 4)\n",
      "(3775, 1, 1, 60)\n",
      "(3775, 7)\n",
      "0 WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (31, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (31, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (31, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60, 4) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60, 4), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (31, 60, 60, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (31, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 7) for input KerasTensor(type_spec=TensorSpec(shape=(32, 7), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (31, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (22, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (22, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (22, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60, 4) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60, 4), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (22, 60, 60, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (22, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 7) for input KerasTensor(type_spec=TensorSpec(shape=(32, 7), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (22, 7).\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 {'avg': 0.45509099750129733, 'avg_pcs': 0.4191252759524754, 'avg_rc': 0.5085894039699009, 'fruity': 0.6075387921259627, 'sweet': 0.4481792894934086, 'green': 0.42815250179941294, 'floral': 0.46308725251307786, 'woody': 0.5174129195137899, 'herbaceous': 0.23376623139873592, 'fatty': 0.4874999956646933}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x7fbf9c3676d0>,\n",
       " {'avg': 0.45509099750129733,\n",
       "  'avg_pcs': 0.4191252759524754,\n",
       "  'avg_rc': 0.5085894039699009,\n",
       "  'fruity': 0.6075387921259627,\n",
       "  'sweet': 0.4481792894934086,\n",
       "  'green': 0.42815250179941294,\n",
       "  'floral': 0.46308725251307786,\n",
       "  'woody': 0.5174129195137899,\n",
       "  'herbaceous': 0.23376623139873592,\n",
       "  'fatty': 0.4874999956646933})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.modelTrain2(hpara, epochs=150, batch_size=32, record_dir=record_dir, save_threshold=0.52, save_path=weight_path, normal_init=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dict = {\n",
    "    '0': 'cCc',\n",
    "    '1': 'CC(C)(C)C',\n",
    "    '2': 'CC(C)C', # 三叉的碳\n",
    "    '3': 'C1=CCCC1', # 五元环带个双键\n",
    "    '4': 'C12CC(CC1)CC2',\n",
    "    '5': '[CD4]',\n",
    "    '6': '[r5]',\n",
    "    '7': '[r4]',\n",
    "    '8': 'C1CCC1',\n",
    "    '9': 'C1CCCC1',\n",
    "    '10': 'C(=O)O&&CC(C)C',\n",
    "    '11': 'C(=O)O&&[r5]',\n",
    "    '12': 'C=C-C=C&&CC(C)C',\n",
    "    '13': 'SS',\n",
    "    '14': '[r6]&&[r5]',\n",
    "}\n",
    "\n",
    "od_name = []\n",
    "sub_list = []\n",
    "for sub in sub_dict:\n",
    "    od_name.append(sub)\n",
    "    sub_list.append(sub_dict[sub])\n",
    "\n",
    "otherpairs = [[12,14]]\n",
    "od_name.append('12or14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_mol = [6, 79, 134, 141, 205, 220, 353, 382, 447, 520, 636, 741, 746, 767, 787, 835, 839, 850, 918, 958, 991, 1039, 1064, 1101, 1127, 1168, 1193, 1237, 1248, 1252, 1277, 1496, 1500, 1517, 1526, 1574, 1584, 1610, 1630, 1659, 1675, 1815, 1831, 1839, 1872, 2031, 2146, 2198, 2233, 2268, 2521, 2592, 2703, 2728, 2756, 2826, 2887, 2940, 2993, 3045, 3128, 3141, 3170, 3178, 3202, 3291, 3310, 3457, 3489, 3529, 3652, 3720, 3779, 3800, 3809, 3818, 3923, 3998, 4033, 4119, 4149, 4153, 4183, 4227, 4327, 4428, 4429, 4475, 4515, 4603, 4697, 4745, 4748, 4762, 4842, 4846, 4852, 4907, 4931, 4976, 5067, 5314, 5346, 5398, 5428, 5434, 5461, 5582, 5636, 5649, 5671, 5738, 5806, 5894, 5961, 6111, 6169, 6176, 6249, 6296, 6361, 6379, 6416, 6439, 6529, 6675, 6686, 6687, 6696, 6927, 6970, 7033, 7109, 7126, 7198, 7226, 7262, 7295, 7318, 7351, 7404, 7439, 7478, 7556, 7561, 7591, 7631, 7672, 7686, 7714, 7890, 7949, 7955, 7978, 8177, 8185, 8240, 8257, 8278, 8289, 8427, 8516, 8668, 8732, 8867, 8874, 8941, 8980, 9253, 9258, 9272, 9310, 9366, 9467, 9594, 9639, 9710, 9928, 9940, 9964, 10103, 10124, 10355, 10407, 10470, 10599, 10602, 10638, 10664, 10705, 10765, 10815, 10851, 11031, 11043, 11119, 11142, 11246, 11279, 11280, 11354, 11390, 11396, 11484, 11554, 11591, 11621, 11752, 11802, 11975, 11977, 12042, 12089, 12129, 12214, 12244, 12252, 12318, 12350, 12440, 12466, 12475, 12542, 12603, 12708, 12938, 13221, 13231, 13400, 13490, 13506, 13668, 13706, 13765, 13775, 13916, 14060, 14191, 14203, 14469, 14495, 14539, 14555, 14604, 14804, 14843, 14848, 14897, 15080, 15111, 15137, 15211, 15279, 15350, 15378, 15397, 15416, 15425, 15458, 15560, 15656, 15808, 15841, 15907, 15918, 15983, 16125, 16144, 16256, 16404, 16440, 16460, 16594, 16621, 16827, 17081, 17175, 17227, 17495, 17551, 17578, 17633, 17655, 17685, 17689, 17726, 17812, 17901, 17902, 17950, 17964, 18046, 18050, 18106, 18111, 18112, 18137, 18186, 18204, 18461, 18534, 18542, 18558, 18628, 18720, 18845, 19105, 19169, 19210, 19238, 19254, 19289, 19301, 19305, 19324, 19344, 19349, 19449, 19478, 19707, 19764, 19780, 19961, 20024, 20142, 20190, 20213, 20224, 20311, 20432, 20463, 20490, 20500, 20747, 20842, 20900, 21106, 21119, 21167, 21231, 21239, 21384, 21462, 21530, 21593, 21642, 21724, 21837, 21851, 21874, 22061, 22104, 22172, 22327, 22336, 22407, 22420, 22558, 22574, 22593, 22601, 22629, 22725, 22782, 22817, 22837, 22935, 22941, 23305, 23389, 23466, 23565, 23600, 23724, 23743, 23817, 23818, 23819, 23999, 24167, 24196, 24201, 24214, 24240, 24246, 24308, 24375, 24452, 24567, 24571, 24579, 24613, 24625, 24628, 24643, 24646, 24742, 24857, 24867, 24975, 25215, 25219, 25276, 25277, 25416, 25421, 25427, 25446, 25519, 25671, 25689, 25746, 25751, 25765, 25806, 25848, 25958, 25965, 26016, 26179, 26338, 26352, 26397, 26497, 26607, 26712, 26713, 26714, 26717, 26736, 26820, 26839, 26844, 27067, 27126, 27156, 27189, 27202, 27213, 27224, 27229, 27264, 27302, 27347, 27390, 27406, 27422, 27521, 27613, 27718, 27825, 27837, 27846, 27917, 27969, 28013, 28067, 28085, 28103, 28135, 28152, 28157, 28250, 28316, 28410, 28567, 28581, 28619, 28645, 28651, 28798, 28853, 28922, 29054, 29088, 29105, 29181, 29269, 29327, 29361, 29428, 29514, 29527, 29547, 29578, 29629, 29630, 29759, 29835, 29880, 29961, 29979, 30005, 30025, 30279, 30316, 30407, 30443, 30762, 30778, 30883, 31042, 31046, 31136, 31138, 31165, 31312, 31413, 31457, 31464, 31530, 31561, 31585, 31617, 31748, 31773, 31818, 31835, 31845, 31853, 31882, 31901, 31951, 32042, 32253, 32306, 32321, 32354, 32387, 32510, 32540, 32648, 32722, 32788, 32807, 32868, 32892, 32958, 32968, 32985, 33037, 33042, 33172, 33263, 33309, 33366, 33374, 33380, 33394, 33427, 33491, 33528, 33570, 33601, 33819, 33829, 33863, 33926, 33954, 34053, 34106, 34312, 34366, 34429, 34628, 34633, 34823, 34884, 35075, 35094, 35115, 35206, 35246, 35273, 35300, 35490, 35525, 35535, 35647, 35649, 35671, 35780, 35870, 35931, 36083, 36171, 36177, 36201, 36216, 36289, 36329, 36335, 36402, 36453, 36534, 36705, 36815, 36822, 36842, 36889, 36902, 36944, 36961, 37108, 37121, 37297, 37304, 37462, 37500, 37596, 37607, 37697, 37710, 37781, 37900, 38027, 38046, 38052, 38062, 38365, 38415, 38440, 38485, 38533, 38548, 38757, 38879, 38890, 39111, 39232, 39270, 39316, 39410, 39459, 39523, 39537, 39660, 39832, 40008, 40053, 40152, 40254, 40283, 40323, 40398, 40488, 40502, 40520, 40547, 40586, 40601, 40685, 40702, 40774, 40828, 40867, 40950, 40976, 40990, 41012, 41045, 41058, 41143, 41201, 41290, 41305, 41306, 41318, 41350, 41458, 41459, 41474, 41485, 41609, 41652, 41663, 41784, 41876, 41906, 41927, 42201, 42252, 42301, 42358, 42375, 42504, 42546, 42552, 42587, 42661, 42662, 42666, 42668, 42734, 42791, 42808, 42814, 42865, 42869, 42882, 42950, 42952, 42976, 43004, 43022, 43050, 43180, 43194, 43219, 43357, 43466, 43471, 43503, 43678, 43681, 43773, 43792, 43856, 43882, 43979, 43994, 44174, 44208, 44270, 44311, 44361, 44416, 44449, 44459, 44461, 44462, 44466, 44470, 44473, 44503, 44514, 44565, 44572, 44714, 44730, 44788, 44868, 44919, 44941, 45004, 45029, 45033, 45045, 45115, 45144, 45155, 45218, 45366, 45367, 45505, 45541, 45602, 45619, 45697, 45776, 45831, 45833, 45835, 45893, 45915, 45992, 46102, 46227, 46334, 46383, 46412, 46465, 46487, 46494, 46507, 46608, 46671, 46763, 46804, 46834, 46981, 46984, 47071, 47171, 47187, 47218, 47232, 47346, 47416, 47443, 47454, 47494, 47581, 47666, 47704, 47838, 47907, 47941, 47944, 47968, 48063, 48119, 48182, 48193, 48199, 48280, 48345, 48346, 48389, 48480, 48567, 48643, 48697, 48708, 48709, 48736, 48800, 48878, 48889, 48935, 48963, 49039, 49050, 49160, 49203, 49222, 49249, 49273, 49281, 49302, 49330, 49355, 49478, 49517, 49542, 49544, 49600, 49615, 49704, 49713, 49831, 49845, 49947, 49988, 50030, 50147, 50271, 50391, 50405, 50499, 50585, 50610, 50623, 50658, 50729, 50761, 50870, 51001, 51231, 51288, 51327, 51361, 51390, 51416, 51458, 51493, 51509, 51535, 51549, 51606, 51639, 51735, 51774, 51801, 51810, 51819, 51935, 52010, 52081, 52145, 52154, 52178, 52206, 52220, 52383, 52478, 52489, 52536, 52677, 52681, 52845, 52873, 52880, 52896, 53081, 53189, 53222, 53300, 53389, 53422, 53480, 53500, 53568, 53598, 53676, 53862, 53897, 53901, 53951, 54019, 54056, 54151, 54385, 54394, 54418, 54535, 54676, 54683, 54813, 54844, 55036, 55301, 55337, 55506, 55516, 55538, 55546, 55583, 55629, 55735, 55756, 55795, 55859, 55998, 56003, 56011, 56094, 56214, 56282, 56430, 56469, 56524, 56528, 56535, 56595, 56723, 56807, 56837, 56876, 56981, 57017, 57051, 57275, 57384, 57474, 57689, 57776, 57843, 57940, 58025, 58063, 58112, 58289, 58395, 58531, 58550, 58558, 58573, 58622, 58781, 58786, 58950, 58959, 59104, 59122, 59138, 59230, 59263, 59568, 59651, 59666, 59669, 59888, 60019, 60056, 60079, 60111, 60119, 60141, 60157, 60252, 60651, 60664, 60676, 60713, 60844, 61017, 61104, 61164, 61302, 61320, 61359, 61465, 61504, 61569, 61592, 61912, 61961, 61986, 62001, 62028, 62240, 62320, 62404, 62435, 62497, 62507, 62739, 62768, 62870, 62924, 63131, 63140, 63185, 63208, 63227, 63379, 63383, 63393, 63548, 63587, 63693, 63716, 63724, 63749, 63753, 63772, 63847, 63864, 63896, 63944, 63951, 64046, 64097, 64100, 64180, 64186, 64188, 64260, 64329, 64365, 64408, 64471, 64602, 64683, 64692, 64833, 65024, 65146, 65174, 65179, 65294, 65313, 65403, 65412, 65419, 65432, 65438, 65470, 65534, 65596, 65675, 65787, 65871, 65924, 65928, 65938, 65961, 66005, 66027, 66029, 66033, 66046, 66050, 66093, 66096, 66116, 66157, 66197, 66367, 66368, 66463, 66496, 66525, 66577, 66631, 66660, 66699, 66921, 66939, 66956, 66974, 67005, 67019, 67084, 67118, 67154, 67282, 67291, 67334, 67336, 67353, 67386, 67509, 67510, 67512, 67522, 67585, 67627, 67684, 67725, 67735, 67744, 67786, 67849, 67850, 67889, 67943, 68038, 68151, 68158, 68314, 68354, 68379, 68453, 68489, 68610, 68880, 68906, 69007, 69052, 69067, 69132, 69223, 69238, 69345, 69429, 69487, 69491, 69557, 69619, 69713, 69728, 69892, 69926, 69928, 70094, 70118, 70129, 70173, 70353, 70520, 70649, 70688, 70816, 70936, 70969, 70970, 70977, 70980, 70989, 71009, 71091, 71158, 71232, 71244, 71285, 71288, 71387, 71535, 71588, 71625, 71863, 72032, 72221, 72225, 72311, 72321, 72333, 72576, 72668, 72729, 72754, 72847, 72884, 72915, 72936, 72942, 73013, 73047, 73153, 73185, 73220, 73249, 73291, 73408, 73508, 73538, 73582, 73596, 73599, 73616, 73739, 73770, 73781, 74008, 74078, 74168, 74264, 74377, 74496, 74517, 74572, 74577, 74628, 74646, 74704, 74710, 74720, 74732, 74740, 74860, 74994, 75034, 75040, 75071, 75119, 75163, 75195, 75311, 75376, 75378, 75511, 75544, 75600, 75781, 75822, 75870, 75927, 75929, 75941, 76232, 76295, 76310, 76354, 76376, 76422, 76564, 76882, 76903, 77065, 77130, 77147, 77157, 77202, 77248, 77309, 77342, 77410, 77532, 77546, 77560, 77632, 77658, 77749, 77785, 77922, 77958, 78088, 78103, 78104, 78203, 78213, 78251, 78273, 78287, 78311, 78514, 78578, 78689, 78698, 78775, 78843, 79048, 79082, 79108, 79130, 79142, 79274, 79282, 79457, 79482, 79519, 79597, 79646, 79797, 79805, 79824, 79883, 79893, 79921, 80077, 80080, 80111, 80122, 80125, 80181, 80233, 80244, 80258, 80277, 80287, 80291, 80312, 80319, 80470, 80554, 80558, 80563, 80610, 80669, 80703, 80975, 80995, 81026, 81103, 81104, 81160, 81221, 81256, 81262, 81341, 81354, 81361, 81387, 81397, 81436, 81461, 81470, 81478, 81542, 81547, 81571, 81634, 81641, 81655, 81701, 81713, 81720, 81933, 81970, 81977, 81999, 82097, 82099, 82105, 82231, 82291, 82376, 82391, 82448, 82548, 82560, 82754, 82869, 82974, 82987, 83019, 83060, 83080, 83131, 83132, 83215, 83229, 83436, 83467, 83474, 83590, 83649, 83681, 83701, 83759, 83771, 83960, 84107, 84162, 84174, 84215, 84220, 84254, 84287, 84297, 84375, 84449, 84454, 84456, 84465, 84470, 84618, 84670, 84680, 84793, 84871, 84981, 85061, 85081, 85132, 85138, 85177, 85275, 85389, 85391, 85435, 85439, 85558, 85716, 85722, 85745, 85900, 85908, 85972, 86062, 86127, 86290, 86381, 86418, 86485, 86504, 86565, 86589, 86622, 86645, 86694, 86746, 86764, 86786, 86888, 87013, 87029, 87071, 87118, 87153, 87163, 87237, 87354, 87405, 87567, 87753, 87755, 87770, 87782, 87783, 87835, 87856, 87877, 87939, 87965, 87982, 88016, 88139, 88179, 88232, 88381, 88435, 88448, 88479, 88658, 88710, 88718, 88888, 88980, 89006, 89123, 89132, 89150, 89204, 89211, 89288, 89445, 89474, 89573, 89671, 89708, 89849, 89884, 90115, 90139, 90299, 90376, 90383, 90540, 90557, 90605, 90623, 90646, 90668, 90732, 90744, 90765, 90772, 90828, 90872, 90921, 90943, 91309, 91371, 91492, 91496, 91515, 91581, 91651, 91807, 91886, 91948, 92101, 92116, 92117, 92151, 92191, 92233, 92238, 92248, 92290, 92364, 92572, 92669, 92676, 92700, 92812, 92864, 92911, 92950, 92988, 93105, 93260, 93340, 93380, 93427, 93594, 93607, 93689, 93787, 93874, 93914, 93939, 93964, 94080, 94182, 94333, 94427, 94490, 94567, 94625, 94755, 94804, 94819, 94899, 94930, 94982, 94995, 95010, 95011, 95015, 95093, 95254, 95273, 95331, 95382, 95475, 95537, 95542, 95602, 95643, 95666, 95748, 95756, 95883, 95933, 95953, 96036, 96044, 96072, 96108, 96136, 96149, 96217, 96243, 96274, 96284, 96293, 96308, 96338, 96493, 96497, 96571, 96576, 96593, 96659, 96732, 96738, 96810, 96824, 96871, 96898, 96909, 96943, 96992, 97006, 97029, 97035, 97052, 97056, 97110, 97153, 97219, 97230, 97237, 97407, 97504, 97529, 97549, 97571, 97588, 97713, 97745, 97800, 97897, 97918, 97985, 98005, 98198, 98229, 98232, 98249, 98328, 98349, 98511, 98719, 98811, 98822, 98872, 98903, 98931, 98933, 99043, 99068, 99151, 99165, 99204, 99300, 99324, 99328, 99355, 99416, 99452, 99464, 99468, 99476, 99504, 99543, 99741, 99775, 99796, 99915, 99926, 99995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer2sub\n",
      "Transformer2OD_tada\n",
      "transformer2od\n",
      "1676 mol cannot compute distance, they are: [6, 79, 134, 141, 205, 220, 353, 382, 447, 520, 636, 741, 746, 767, 787, 835, 839, 850, 918, 958, 991, 1039, 1064, 1101, 1127, 1168, 1193, 1237, 1248, 1252, 1277, 1496, 1500, 1517, 1526, 1574, 1584, 1610, 1630, 1659, 1675, 1815, 1831, 1839, 1872, 2031, 2146, 2198, 2233, 2268, 2521, 2592, 2703, 2728, 2756, 2826, 2887, 2940, 2993, 3045, 3128, 3141, 3170, 3178, 3202, 3291, 3310, 3457, 3489, 3529, 3652, 3720, 3779, 3800, 3809, 3818, 3923, 3998, 4033, 4119, 4149, 4153, 4183, 4227, 4327, 4428, 4429, 4475, 4515, 4603, 4697, 4745, 4748, 4762, 4842, 4846, 4852, 4907, 4931, 4976, 5067, 5314, 5346, 5398, 5428, 5434, 5461, 5582, 5636, 5649, 5671, 5738, 5806, 5894, 5961, 6111, 6169, 6176, 6249, 6296, 6361, 6379, 6416, 6439, 6529, 6675, 6686, 6687, 6696, 6927, 6970, 7033, 7109, 7126, 7198, 7226, 7262, 7295, 7318, 7351, 7404, 7439, 7478, 7556, 7561, 7591, 7631, 7672, 7686, 7714, 7890, 7949, 7955, 7978, 8177, 8185, 8240, 8257, 8278, 8289, 8427, 8516, 8668, 8732, 8867, 8874, 8941, 8980, 9253, 9258, 9272, 9310, 9366, 9467, 9594, 9639, 9710, 9928, 9940, 9964, 10103, 10124, 10355, 10407, 10470, 10599, 10602, 10638, 10664, 10705, 10765, 10815, 10851, 11031, 11043, 11119, 11142, 11246, 11279, 11280, 11354, 11390, 11396, 11484, 11554, 11591, 11621, 11752, 11802, 11975, 11977, 12042, 12089, 12129, 12214, 12244, 12252, 12318, 12350, 12440, 12466, 12475, 12542, 12603, 12708, 12938, 13221, 13231, 13400, 13490, 13506, 13668, 13706, 13765, 13775, 13916, 14060, 14191, 14203, 14469, 14495, 14539, 14555, 14604, 14804, 14843, 14848, 14897, 15080, 15111, 15137, 15211, 15279, 15350, 15378, 15397, 15416, 15425, 15458, 15560, 15656, 15808, 15841, 15907, 15918, 15983, 16125, 16144, 16256, 16404, 16440, 16460, 16594, 16621, 16827, 17081, 17175, 17227, 17495, 17551, 17578, 17633, 17655, 17685, 17689, 17726, 17812, 17901, 17902, 17950, 17964, 18046, 18050, 18106, 18111, 18112, 18137, 18186, 18204, 18461, 18534, 18542, 18558, 18628, 18720, 18845, 19105, 19169, 19210, 19238, 19254, 19289, 19301, 19305, 19324, 19344, 19349, 19449, 19478, 19707, 19764, 19780, 19961, 20024, 20142, 20190, 20213, 20224, 20311, 20432, 20463, 20490, 20500, 20747, 20842, 20900, 21106, 21119, 21167, 21231, 21239, 21384, 21462, 21530, 21593, 21642, 21724, 21837, 21851, 21874, 22061, 22104, 22172, 22327, 22336, 22407, 22420, 22558, 22574, 22593, 22601, 22629, 22725, 22782, 22817, 22837, 22935, 22941, 23305, 23389, 23466, 23565, 23600, 23724, 23743, 23817, 23818, 23819, 23999, 24167, 24196, 24201, 24214, 24240, 24246, 24308, 24375, 24452, 24567, 24571, 24579, 24613, 24625, 24628, 24643, 24646, 24742, 24857, 24867, 24975, 25215, 25219, 25276, 25277, 25416, 25421, 25427, 25446, 25519, 25671, 25689, 25746, 25751, 25765, 25806, 25848, 25958, 25965, 26016, 26179, 26338, 26352, 26397, 26497, 26607, 26712, 26713, 26714, 26717, 26736, 26820, 26839, 26844, 27067, 27126, 27156, 27189, 27202, 27213, 27224, 27229, 27264, 27302, 27347, 27390, 27406, 27422, 27521, 27613, 27718, 27825, 27837, 27846, 27917, 27969, 28013, 28067, 28085, 28103, 28135, 28152, 28157, 28250, 28316, 28410, 28567, 28581, 28619, 28645, 28651, 28798, 28853, 28922, 29054, 29088, 29105, 29181, 29269, 29327, 29361, 29428, 29514, 29527, 29547, 29578, 29629, 29630, 29759, 29835, 29880, 29961, 29979, 30005, 30025, 30279, 30316, 30407, 30443, 30762, 30778, 30883, 31042, 31046, 31136, 31138, 31165, 31312, 31413, 31457, 31464, 31530, 31561, 31585, 31617, 31748, 31773, 31818, 31835, 31845, 31853, 31882, 31901, 31951, 32042, 32253, 32306, 32321, 32354, 32387, 32510, 32540, 32648, 32722, 32788, 32807, 32868, 32892, 32958, 32968, 32985, 33037, 33042, 33172, 33263, 33309, 33366, 33374, 33380, 33394, 33427, 33491, 33528, 33570, 33601, 33819, 33829, 33863, 33926, 33954, 34053, 34106, 34312, 34366, 34429, 34628, 34633, 34823, 34884, 35075, 35094, 35115, 35206, 35246, 35273, 35300, 35490, 35525, 35535, 35647, 35649, 35671, 35780, 35870, 35931, 36083, 36171, 36177, 36201, 36216, 36289, 36329, 36335, 36402, 36453, 36534, 36705, 36815, 36822, 36842, 36889, 36902, 36944, 36961, 37108, 37121, 37297, 37304, 37462, 37500, 37596, 37607, 37697, 37710, 37781, 37900, 38027, 38046, 38052, 38062, 38365, 38415, 38440, 38485, 38533, 38548, 38757, 38879, 38890, 39111, 39232, 39270, 39316, 39410, 39459, 39523, 39537, 39660, 39832, 40008, 40053, 40152, 40254, 40283, 40323, 40398, 40488, 40502, 40520, 40547, 40586, 40601, 40685, 40702, 40774, 40828, 40867, 40950, 40976, 40990, 41012, 41045, 41058, 41143, 41201, 41290, 41305, 41306, 41318, 41350, 41458, 41459, 41474, 41485, 41609, 41652, 41663, 41784, 41876, 41906, 41927, 42201, 42252, 42301, 42358, 42375, 42504, 42546, 42552, 42587, 42661, 42662, 42666, 42668, 42734, 42791, 42808, 42814, 42865, 42869, 42882, 42950, 42952, 42976, 43004, 43022, 43050, 43180, 43194, 43219, 43357, 43466, 43471, 43503, 43678, 43681, 43773, 43792, 43856, 43882, 43979, 43994, 44174, 44208, 44270, 44311, 44361, 44416, 44449, 44459, 44461, 44462, 44466, 44470, 44473, 44503, 44514, 44565, 44572, 44714, 44730, 44788, 44868, 44919, 44941, 45004, 45029, 45033, 45045, 45115, 45144, 45155, 45218, 45366, 45367, 45505, 45541, 45602, 45619, 45697, 45776, 45831, 45833, 45835, 45893, 45915, 45992, 46102, 46227, 46334, 46383, 46412, 46465, 46487, 46494, 46507, 46608, 46671, 46763, 46804, 46834, 46981, 46984, 47071, 47171, 47187, 47218, 47232, 47346, 47416, 47443, 47454, 47494, 47581, 47666, 47704, 47838, 47907, 47941, 47944, 47968, 48063, 48119, 48182, 48193, 48199, 48280, 48345, 48346, 48389, 48480, 48567, 48643, 48697, 48708, 48709, 48736, 48800, 48878, 48889, 48935, 48963, 49039, 49050, 49160, 49203, 49222, 49249, 49273, 49281, 49302, 49330, 49355, 49478, 49517, 49542, 49544, 49600, 49615, 49704, 49713, 49831, 49845, 49947, 49988, 50030, 50147, 50271, 50391, 50405, 50499, 50585, 50610, 50623, 50658, 50729, 50761, 50870, 51001, 51231, 51288, 51327, 51361, 51390, 51416, 51458, 51493, 51509, 51535, 51549, 51606, 51639, 51735, 51774, 51801, 51810, 51819, 51935, 52010, 52081, 52145, 52154, 52178, 52206, 52220, 52383, 52478, 52489, 52536, 52677, 52681, 52845, 52873, 52880, 52896, 53081, 53189, 53222, 53300, 53389, 53422, 53480, 53500, 53568, 53598, 53676, 53862, 53897, 53901, 53951, 54019, 54056, 54151, 54385, 54394, 54418, 54535, 54676, 54683, 54813, 54844, 55036, 55301, 55337, 55506, 55516, 55538, 55546, 55583, 55629, 55735, 55756, 55795, 55859, 55998, 56003, 56011, 56094, 56214, 56282, 56430, 56469, 56524, 56528, 56535, 56595, 56723, 56807, 56837, 56876, 56981, 57017, 57051, 57275, 57384, 57474, 57689, 57776, 57843, 57940, 58025, 58063, 58112, 58289, 58395, 58531, 58550, 58558, 58573, 58622, 58781, 58786, 58950, 58959, 59104, 59122, 59138, 59230, 59263, 59568, 59651, 59666, 59669, 59888, 60019, 60056, 60079, 60111, 60119, 60141, 60157, 60252, 60651, 60664, 60676, 60713, 60844, 61017, 61104, 61164, 61302, 61320, 61359, 61465, 61504, 61569, 61592, 61912, 61961, 61986, 62001, 62028, 62240, 62320, 62404, 62435, 62497, 62507, 62739, 62768, 62870, 62924, 63131, 63140, 63185, 63208, 63227, 63379, 63383, 63393, 63548, 63587, 63693, 63716, 63724, 63749, 63753, 63772, 63847, 63864, 63896, 63944, 63951, 64046, 64097, 64100, 64180, 64186, 64188, 64260, 64329, 64365, 64408, 64471, 64602, 64683, 64692, 64833, 65024, 65146, 65174, 65179, 65294, 65313, 65403, 65412, 65419, 65432, 65438, 65470, 65534, 65596, 65675, 65787, 65871, 65924, 65928, 65938, 65961, 66005, 66027, 66029, 66033, 66046, 66050, 66093, 66096, 66116, 66157, 66197, 66367, 66368, 66463, 66496, 66525, 66577, 66631, 66660, 66699, 66921, 66939, 66956, 66974, 67005, 67019, 67084, 67118, 67154, 67282, 67291, 67334, 67336, 67353, 67386, 67509, 67510, 67512, 67522, 67585, 67627, 67684, 67725, 67735, 67744, 67786, 67849, 67850, 67889, 67943, 68038, 68151, 68158, 68314, 68354, 68379, 68453, 68489, 68610, 68880, 68906, 69007, 69052, 69067, 69132, 69223, 69238, 69345, 69429, 69487, 69491, 69557, 69619, 69713, 69728, 69892, 69926, 69928, 70094, 70118, 70129, 70173, 70353, 70520, 70649, 70688, 70816, 70936, 70969, 70970, 70977, 70980, 70989, 71009, 71091, 71158, 71232, 71244, 71285, 71288, 71387, 71535, 71588, 71625, 71863, 72032, 72221, 72225, 72311, 72321, 72333, 72576, 72668, 72729, 72754, 72847, 72884, 72915, 72936, 72942, 73013, 73047, 73153, 73185, 73220, 73249, 73291, 73408, 73508, 73538, 73582, 73596, 73599, 73616, 73739, 73770, 73781, 74008, 74078, 74168, 74264, 74377, 74496, 74517, 74572, 74577, 74628, 74646, 74704, 74710, 74720, 74732, 74740, 74860, 74994, 75034, 75040, 75071, 75119, 75163, 75195, 75311, 75376, 75378, 75511, 75544, 75600, 75781, 75822, 75870, 75927, 75929, 75941, 76232, 76295, 76310, 76354, 76376, 76422, 76564, 76882, 76903, 77065, 77130, 77147, 77157, 77202, 77248, 77309, 77342, 77410, 77532, 77546, 77560, 77632, 77658, 77749, 77785, 77922, 77958, 78088, 78103, 78104, 78203, 78213, 78251, 78273, 78287, 78311, 78514, 78578, 78689, 78698, 78775, 78843, 79048, 79082, 79108, 79130, 79142, 79274, 79282, 79457, 79482, 79519, 79597, 79646, 79797, 79805, 79824, 79883, 79893, 79921, 80077, 80080, 80111, 80122, 80125, 80181, 80233, 80244, 80258, 80277, 80287, 80291, 80312, 80319, 80470, 80554, 80558, 80563, 80610, 80669, 80703, 80975, 80995, 81026, 81103, 81104, 81160, 81221, 81256, 81262, 81341, 81354, 81361, 81387, 81397, 81436, 81461, 81470, 81478, 81542, 81547, 81571, 81634, 81641, 81655, 81701, 81713, 81720, 81933, 81970, 81977, 81999, 82097, 82099, 82105, 82231, 82291, 82376, 82391, 82448, 82548, 82560, 82754, 82869, 82974, 82987, 83019, 83060, 83080, 83131, 83132, 83215, 83229, 83436, 83467, 83474, 83590, 83649, 83681, 83701, 83759, 83771, 83960, 84107, 84162, 84174, 84215, 84220, 84254, 84287, 84297, 84375, 84449, 84454, 84456, 84465, 84470, 84618, 84670, 84680, 84793, 84871, 84981, 85061, 85081, 85132, 85138, 85177, 85275, 85389, 85391, 85435, 85439, 85558, 85716, 85722, 85745, 85900, 85908, 85972, 86062, 86127, 86290, 86381, 86418, 86485, 86504, 86565, 86589, 86622, 86645, 86694, 86746, 86764, 86786, 86888, 87013, 87029, 87071, 87118, 87153, 87163, 87237, 87354, 87405, 87567, 87753, 87755, 87770, 87782, 87783, 87835, 87856, 87877, 87939, 87965, 87982, 88016, 88139, 88179, 88232, 88381, 88435, 88448, 88479, 88658, 88710, 88718, 88888, 88980, 89006, 89123, 89132, 89150, 89204, 89211, 89288, 89445, 89474, 89573, 89671, 89708, 89849, 89884, 90115, 90139, 90299, 90376, 90383, 90540, 90557, 90605, 90623, 90646, 90668, 90732, 90744, 90765, 90772, 90828, 90872, 90921, 90943, 91309, 91371, 91492, 91496, 91515, 91581, 91651, 91807, 91886, 91948, 92101, 92116, 92117, 92151, 92191, 92233, 92238, 92248, 92290, 92364, 92572, 92669, 92676, 92700, 92812, 92864, 92911, 92950, 92988, 93105, 93260, 93340, 93380, 93427, 93594, 93607, 93689, 93787, 93874, 93914, 93939, 93964, 94080, 94182, 94333, 94427, 94490, 94567, 94625, 94755, 94804, 94819, 94899, 94930, 94982, 94995, 95010, 95011, 95015, 95093, 95254, 95273, 95331, 95382, 95475, 95537, 95542, 95602, 95643, 95666, 95748, 95756, 95883, 95933, 95953, 96036, 96044, 96072, 96108, 96136, 96149, 96217, 96243, 96274, 96284, 96293, 96308, 96338, 96493, 96497, 96571, 96576, 96593, 96659, 96732, 96738, 96810, 96824, 96871, 96898, 96909, 96943, 96992, 97006, 97029, 97035, 97052, 97056, 97110, 97153, 97219, 97230, 97237, 97407, 97504, 97529, 97549, 97571, 97588, 97713, 97745, 97800, 97897, 97918, 97985, 98005, 98198, 98229, 98232, 98249, 98328, 98349, 98511, 98719, 98811, 98822, 98872, 98903, 98931, 98933, 99043, 99068, 99151, 99165, 99204, 99300, 99324, 99328, 99355, 99416, 99452, 99464, 99468, 99476, 99504, 99543, 99741, 99775, 99796, 99915, 99926, 99995]\n",
      "num_sample : 98324\n",
      "mask_mat: (98324, 1, 1, 60)\n",
      "mol_atom_feat.shape: (98324, 60, 71)\n",
      "distance value type is: exp\n",
      "all_adj.shape = : (98324, 60, 60)\n",
      "all_dist.shape = : (98324, 60, 60)\n",
      "od_shuffled.shape =  (98324, 16)\n",
      "positive sample distribution in test set:\n",
      "{'0': 1110.0, '1': 913.0, '2': 4325.0, '3': 73.0, '4': 39.0, '5': 3850.0, '6': 9836.0, '7': 354.0, '8': 131.0, '9': 544.0, '10': 1407.0, '11': 2144.0, '12': 85.0, '13': 33.0, '14': 9481.0, '12or14': 9521.0}\n",
      "positive sample distribution in test set:\n",
      "{'0': 5646.0, '1': 4531.0, '2': 21496.0, '3': 408.0, '4': 184.0, '5': 19257.0, '6': 49538.0, '7': 1897.0, '8': 691.0, '9': 2718.0, '10': 6920.0, '11': 10678.0, '12': 474.0, '13': 136.0, '14': 47736.0, '12or14': 47949.0}\n"
     ]
    }
   ],
   "source": [
    "test = Haha.Transformer2Sub()\n",
    "test.molData_atomicF(smiles_list, dist_value='exp', atomH=False, failed_mol=None, rseed=0)\n",
    "# test.molData(smiles_list, dist_value='exp', atomH=False)\n",
    "test.odData(smiles_list, sub_list=sub_list, od_name=od_name, otherpairs=otherpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "\n",
    "hpara = {\n",
    "            'num_heads': 6,\n",
    "            'single_attn_dim': 30,\n",
    "            'num_encoderLayer': 5,\n",
    "            'num_decoderLayer': 1, \n",
    "            'learning_rate': 0.00003, \n",
    "            'temperature': 0.7\n",
    "        }\n",
    "\n",
    "record_dir='/tf/haha/code/logs/0719/sub100k-6_30_51'\n",
    "\n",
    "weight_path = '/tf/haha/save_weight/0719/sub100k-6_30_51/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/haha/code/logs/0719/sub100k-6_30_51\n",
      "modelBuild2-temperature 0.700000\n",
      "(81935, 1, 1)\n",
      "(81935, 60, 71)\n",
      "(81935, 60, 60)\n",
      "(81935, 60, 60)\n",
      "(81935, 1, 1, 60)\n",
      "(81935, 16)\n",
      "0 WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (15, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (15, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (15, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (15, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (15, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 16) for input KerasTensor(type_spec=TensorSpec(shape=(32, 16), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (15, 16).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (5, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (5, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (5, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (5, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (5, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 16) for input KerasTensor(type_spec=TensorSpec(shape=(32, 16), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (5, 16).\n",
      "1 2 3 4 5 6 7 weight保存开始：Wed Jul 20 10:27:56 2022 weight保存完成 Wed Jul 20 10:27:56 2022\n",
      "8 weight保存开始：Wed Jul 20 10:30:33 2022 weight保存完成 Wed Jul 20 10:30:34 2022\n",
      "9 weight保存开始：Wed Jul 20 10:33:11 2022 weight保存完成 Wed Jul 20 10:33:11 2022\n",
      "10 weight保存开始：Wed Jul 20 10:35:48 2022 weight保存完成 Wed Jul 20 10:35:48 2022\n",
      "11 weight保存开始：Wed Jul 20 10:38:26 2022 weight保存完成 Wed Jul 20 10:38:26 2022\n",
      "12 weight保存开始：Wed Jul 20 10:41:03 2022 weight保存完成 Wed Jul 20 10:41:03 2022\n",
      "13 weight保存开始：Wed Jul 20 10:43:40 2022 weight保存完成 Wed Jul 20 10:43:41 2022\n",
      "14 weight保存开始：Wed Jul 20 10:46:18 2022 weight保存完成 Wed Jul 20 10:46:18 2022\n",
      "15 16 weight保存开始：Wed Jul 20 10:51:32 2022 weight保存完成 Wed Jul 20 10:51:33 2022\n",
      "17 weight保存开始：Wed Jul 20 10:54:10 2022 weight保存完成 Wed Jul 20 10:54:10 2022\n",
      "18 19 weight保存开始：Wed Jul 20 10:59:24 2022 weight保存完成 Wed Jul 20 10:59:24 2022\n",
      "20 weight保存开始：Wed Jul 20 11:02:02 2022 weight保存完成 Wed Jul 20 11:02:02 2022\n",
      "21 22 weight保存开始：Wed Jul 20 11:07:16 2022 weight保存完成 Wed Jul 20 11:07:17 2022\n",
      "23 24 weight保存开始：Wed Jul 20 11:12:31 2022 weight保存完成 Wed Jul 20 11:12:31 2022\n",
      "25 weight保存开始：Wed Jul 20 11:15:08 2022 weight保存完成 Wed Jul 20 11:15:08 2022\n",
      "26 27 28 weight保存开始：Wed Jul 20 11:23:00 2022 weight保存完成 Wed Jul 20 11:23:00 2022\n",
      "29 30 31 32 33 weight保存开始：Wed Jul 20 11:36:08 2022 weight保存完成 Wed Jul 20 11:36:08 2022\n",
      "34 35 weight保存开始：Wed Jul 20 11:41:23 2022 weight保存完成 Wed Jul 20 11:41:23 2022\n",
      "36 weight保存开始：Wed Jul 20 11:44:01 2022 weight保存完成 Wed Jul 20 11:44:01 2022\n",
      "37 38 39 40 weight保存开始：Wed Jul 20 11:54:31 2022 weight保存完成 Wed Jul 20 11:54:31 2022\n",
      "41 42 43 44 45 46 47 48 49 50 weight保存开始：Wed Jul 20 12:20:46 2022 weight保存完成 Wed Jul 20 12:20:46 2022\n",
      "51 52 weight保存开始：Wed Jul 20 12:26:01 2022 weight保存完成 Wed Jul 20 12:26:01 2022\n",
      "53 weight保存开始：Wed Jul 20 12:28:39 2022 weight保存完成 Wed Jul 20 12:28:39 2022\n",
      "54 55 weight保存开始：Wed Jul 20 12:33:55 2022 weight保存完成 Wed Jul 20 12:33:55 2022\n",
      "56 57 58 59 weight保存开始：Wed Jul 20 12:44:25 2022 weight保存完成 Wed Jul 20 12:44:26 2022\n",
      "60 weight保存开始：Wed Jul 20 12:47:03 2022 weight保存完成 Wed Jul 20 12:47:04 2022\n",
      "61 62 63 64 65 66 67 weight保存开始：Wed Jul 20 13:05:26 2022 weight保存完成 Wed Jul 20 13:05:26 2022\n",
      "68 69 weight保存开始：Wed Jul 20 13:10:41 2022 weight保存完成 Wed Jul 20 13:10:42 2022\n",
      "70 71 72 73 74 75 weight保存开始：Wed Jul 20 13:26:27 2022 weight保存完成 Wed Jul 20 13:26:27 2022\n",
      "76 77 78 79 80 81 82 weight保存开始：Wed Jul 20 13:44:50 2022 weight保存完成 Wed Jul 20 13:44:51 2022\n",
      "83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 weight保存开始：Wed Jul 20 14:32:09 2022 weight保存完成 Wed Jul 20 14:32:09 2022\n",
      "101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 weight保存开始：Wed Jul 20 15:32:34 2022 weight保存完成 Wed Jul 20 15:32:35 2022\n",
      "124 125 weight保存开始：Wed Jul 20 15:37:50 2022 weight保存完成 Wed Jul 20 15:37:50 2022\n",
      "126 127 128 129 130 weight保存开始：Wed Jul 20 15:50:59 2022 weight保存完成 Wed Jul 20 15:51:00 2022\n",
      "131 132 133 134 135 136 137 weight保存开始：Wed Jul 20 16:09:23 2022 weight保存完成 Wed Jul 20 16:09:23 2022\n",
      "138 139 140 weight保存开始：Wed Jul 20 16:17:16 2022 weight保存完成 Wed Jul 20 16:17:17 2022\n",
      "141 142 143 144 weight保存开始：Wed Jul 20 16:27:46 2022 weight保存完成 Wed Jul 20 16:27:47 2022\n",
      "145 146 147 148 149 {'avg': 0.9721401376052571, 'avg_pcs': 0.9690013155341148, 'avg_rc': 0.9755745977163315, '0': 0.9995497524980448, '1': 1.0, '2': 1.0, '3': 0.8965517310835376, '4': 0.9135802361209695, '5': 1.0, '6': 0.9969002535341378, '7': 0.9544159581431497, '8': 0.9323308530471938, '9': 0.9543420038434465, '10': 0.9996447493682347, '11': 0.9944160094252004, '12': 0.9523809657446921, '13': 0.9696969985961914, '14': 0.9953655117190482, '12or14': 0.9950671785602645}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x7f37ca4de370>,\n",
       " {'avg': 0.9721401376052571,\n",
       "  'avg_pcs': 0.9690013155341148,\n",
       "  'avg_rc': 0.9755745977163315,\n",
       "  '0': 0.9995497524980448,\n",
       "  '1': 1.0,\n",
       "  '2': 1.0,\n",
       "  '3': 0.8965517310835376,\n",
       "  '4': 0.9135802361209695,\n",
       "  '5': 1.0,\n",
       "  '6': 0.9969002535341378,\n",
       "  '7': 0.9544159581431497,\n",
       "  '8': 0.9323308530471938,\n",
       "  '9': 0.9543420038434465,\n",
       "  '10': 0.9996447493682347,\n",
       "  '11': 0.9944160094252004,\n",
       "  '12': 0.9523809657446921,\n",
       "  '13': 0.9696969985961914,\n",
       "  '14': 0.9953655117190482,\n",
       "  '12or14': 0.9950671785602645})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.modelTrain2(hpara, epochs=150, batch_size=32, record_dir=record_dir, save_threshold=0.7, save_path=weight_path, normal_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([51313 38389 42209 67902 40571 79345 92492 89757 82922 94525], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(test.shuffle_index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avg ec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_output = test.attnExtract(model, num_cls=test.feature_od, trainORtest='test', ecORdc='ec_output', dc_layer=True)\n",
    "# ec_output.shape = (batch, max_mol, d_model)\n",
    "mask = tf.squeeze(test.test_input[4]) # (batch, max_mol)\n",
    "mask = tf.cast(tf.math.equal(mask, 0), tf.float32) # 0,1颠倒 (batch, max_mol)\n",
    "num_a = tf.reduce_sum(mask, axis=-1) # (batch, )\n",
    "mask = tf.expand_dims(mask, axis=-1) # (batch, max_mol, 1)\n",
    "ec_output *= mask # (batch, max_mol, d_model)\n",
    "ec_output = tf.math.l2_normalize(ec_output, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.26454934, shape=(), dtype=float32)\n",
      "tf.Tensor(13.311346, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inner_product = tf.matmul(ec_output, ec_output, transpose_b=True) # (batch, max_mol, max_mol)\n",
    "inner_product = tf.reduce_sum(inner_product, axis=-1) # (batch, max_mol)\n",
    "inner_product = tf.reduce_sum(inner_product, axis=-1) # (batch, )\n",
    "inner_product -= num_a # (batch, )\n",
    "avg_ip = inner_product / (num_a*(num_a)) # (batch, )\n",
    "avg_ip = tf.reduce_sum(avg_ip, axis=0) / num_a.shape[0]\n",
    "avg_numA = tf.reduce_sum(num_a, axis=0) / num_a.shape[0]\n",
    "print(avg_ip)\n",
    "print(avg_numA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attn画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output\n",
    "out_train = []\n",
    "out_test = []\n",
    "for i in range(test.feature_od):\n",
    "    out_train.append(test.od_train[:, i])\n",
    "    out_test.append(test.od_test[:, i])\n",
    "out_train = tuple(out_train)\n",
    "out_test = tuple(out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelBuild2-temperature 0.700000\n"
     ]
    }
   ],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "model = test.modelBuild2(batch_size=32, num_heads=6, single_attn_dim=75, feedforward_dim=450, num_encoderLayer=2, \n",
    "                    num_decoderLayer=4, dropout_rate=0.1, lr=0.00002, compile=True, normal_init=False, temperature=0.7)\n",
    "\n",
    "# model.load_weights('/tf/haha/save_weight/0527/repeat1/7/') # 论文中写的结果\n",
    "# model.load_weights('/tf/haha/save_weight/0719/odMAT-6_30_52/')\n",
    "# model.load_weights('/tf/haha/save_weight/0527/sub5/')\n",
    "model.load_weights('/tf/haha/save_weight/0717/sub100k-6_75_24/')\n",
    "# model.load_weights('/tf/haha/save_weight/0712/sub-10k/')\n",
    "# model.load_weights('/tf/haha/save_weight/0719/od-6_30_52/')\n",
    "# model.load_weights('/tf/haha/save_weight/0719/od-6_30_51/')\n",
    "\n",
    "if len(test.test_input) == test.input_items-1:\n",
    "    test.test_input = list(test.test_input)\n",
    "    test.test_input.append(test.od_test)\n",
    "    test.test_input = tuple(test.test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model(test.test_input)\n",
    "# del pred\n",
    "eva_dict = model.evaluate(test.test_input, out_test, return_dict=True, batch_size=27)\n",
    "print(test.calFscore(eva_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of memory专用\n",
    "temp_input = []\n",
    "for i in test.test_input:\n",
    "    temp_input.append(i[:6400])\n",
    "\n",
    "pred = model.predict(temp_input)\n",
    "\n",
    "test.num_test = 6400\n",
    "attn = pred[-1]\n",
    "savepath = '/tf/haha/img_result/0717/sub6_75_24-dc/'\n",
    "test.drawAttn(attn, smiles_list, pred, savepath, max_draw=50, per_head=False, trainORtest='test', attn_c=0.8, posneg='positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attnDraw\n",
    "attn = test.attnExtract(model, num_cls=test.feature_od, trainORtest='test', dc_layer=True)\n",
    "# attn = [attn[-1]] # if draw each dc layer, delete this line\n",
    "pred = model(test.test_input)\n",
    "# pred = model(test_input_2000)\n",
    "# savepath = '/tf/haha/img_result/0607/6_30_23-500/'\n",
    "# savepath = '/tf/haha/img_result/0607/sub6_30_24/'\n",
    "savepath = '/tf/haha/img_result/0717/sub6_75_24/'\n",
    "test.drawAttn(attn, smiles_list, pred, savepath, max_draw=50, per_head=False, trainORtest='test', attn_c=0.8, posneg='positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attnDraw per head\n",
    "attn = test.attnExtract(model, num_cls=test.feature_od, trainORtest='test', dc_layer=True)\n",
    "attn = [attn[-1]] # if draw each dc layer, delete this line\n",
    "attn[0] = attn[0].numpy()\n",
    "pred = model(test.test_input)\n",
    "savepath = '/tf/haha/img_result/0712/10ksub6_30_24/'\n",
    "test.drawAttn(attn, smiles_list, pred, savepath, max_draw=50, per_head=True, trainORtest='test', attn_c=4, posneg='positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attnProve\n",
    "savepath = '/tf/haha/img_result/0607/attnAvg_k5n50/'\n",
    "\n",
    "weight_path_list = []\n",
    "for i in range(100):\n",
    "    temp = '/tf/haha/save_weight/0527/repeat1/%d/' % i\n",
    "    weight_path_list.append(temp)\n",
    "\n",
    "# test.attnProve(model, weight_path_list, draw_num=60, smiles_list=smiles_list, savepath=savepath, topk=5, atom_appear_times=25)\n",
    "test.attnProve(model, weight_path_list, draw_num=500, smiles_list=smiles_list, savepath=savepath, topk=5, atom_appear_times=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output\n",
    "out_train = []\n",
    "out_test = []\n",
    "for i in range(test.feature_od):\n",
    "    out_train.append(test.od_train[:, i])\n",
    "    out_test.append(test.od_test[:, i])\n",
    "out_train = tuple(out_train)\n",
    "out_test = tuple(out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "model = test.modelBuild2(batch_size=32, num_heads=6, single_attn_dim=30, feedforward_dim=180, num_encoderLayer=3, \n",
    "                    num_decoderLayer=4, dropout_rate=0.1, lr=0.00002, compile=True, normal_init=False, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/tf/haha/save_weight/0518/both/6_30_0.7_34/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(test.test_input) == test.input_items-1:\n",
    "    test.test_input = list(test.test_input)\n",
    "    test.test_input.append(test.od_test)\n",
    "    test.test_input = tuple(test.test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(test.test_input)\n",
    "eva_dict = model.evaluate(test.test_input, out_test, return_dict=True, batch_size=1)\n",
    "print(test.calFscore(eva_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_test[0].shape)\n",
    "print(pred[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = tf.keras.metrics.AUC(\n",
    "    num_thresholds=200,\n",
    "    curve='ROC',\n",
    "    summation_method='interpolation'\n",
    ")\n",
    "\n",
    "roc_dict = {}\n",
    "for i in range(test.feature_od):\n",
    "    od = test.od_name[i]\n",
    "\n",
    "    roc.reset_state()\n",
    "    roc.update_state(out_test[i], pred[i])\n",
    "    temp = roc.result().numpy()\n",
    "    roc_dict[od] = temp\n",
    "print(roc_dict)\n",
    "\n",
    "pr = tf.keras.metrics.AUC(\n",
    "    num_thresholds=200,\n",
    "    curve='PR',\n",
    "    summation_method='interpolation'\n",
    ")\n",
    "\n",
    "pr_dict = {}\n",
    "for i in range(test.feature_od):\n",
    "    od = test.od_name[i]\n",
    "\n",
    "    pr.reset_state()\n",
    "    pr.update_state(out_test[i], pred[i])\n",
    "    temp = pr.result().numpy()\n",
    "    pr_dict[od] = temp\n",
    "print(pr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'MAT'\n",
    "model = test.modelBuild2(batch_size=32, num_heads=6, single_attn_dim=30, feedforward_dim=180, num_encoderLayer=3, \n",
    "                    num_decoderLayer=4, dropout_rate=0.1, lr=0.00002, compile=True, normal_init=False, temperature=0.7)\n",
    "\n",
    "model.load_weights('/tf/haha/save_weight/0519/6_30_0.7_34/')\n",
    "\n",
    "pred = model(test.test_input)\n",
    "eva_dict = model.evaluate(test.test_input, out_test, return_dict=True, batch_size=1)\n",
    "print(test.calFscore(eva_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = tf.keras.metrics.AUC(\n",
    "    num_thresholds=200,\n",
    "    curve='ROC',\n",
    "    summation_method='interpolation'\n",
    ")\n",
    "\n",
    "roc_dict = {}\n",
    "for i in range(test.feature_od):\n",
    "    od = test.od_name[i]\n",
    "\n",
    "    roc.reset_state()\n",
    "    roc.update_state(out_test[i], pred[i])\n",
    "    temp = roc.result().numpy()\n",
    "    roc_dict[od] = temp\n",
    "print(roc_dict)\n",
    "\n",
    "pr = tf.keras.metrics.AUC(\n",
    "    num_thresholds=200,\n",
    "    curve='PR',\n",
    "    summation_method='interpolation'\n",
    ")\n",
    "\n",
    "pr_dict = {}\n",
    "for i in range(test.feature_od):\n",
    "    od = test.od_name[i]\n",
    "\n",
    "    pr.reset_state()\n",
    "    pr.update_state(out_test[i], pred[i])\n",
    "    temp = pr.result().numpy()\n",
    "    pr_dict[od] = temp\n",
    "print(pr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'fruity': 0.860701, 'sweet': 0.8052784, 'green': 0.8206578, 'floral': 0.8363286, 'woody': 0.8615828, 'herbaceous': 0.8133802, \n",
    "'fatty': 0.84928584}\n",
    "\n",
    "{'fruity': 0.7190149, 'sweet': 0.46049345, 'green': 0.53469217, 'floral': 0.52750015, 'woody': 0.5234309, 'herbaceous': 0.35665172, \n",
    "'fatty': 0.5336635}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine_pr_dict = {'fruity': 0.7190149, 'sweet': 0.46049345, 'green': 0.53469217, 'floral': 0.52750015, 'woody': 0.5234309, 'herbaceous': 0.35665172, 'fatty': 0.5336635}\n",
    "MAT_pr_dict = {'fruity': 0.70691204, 'sweet': 0.47980043, 'green': 0.49917567, 'floral': 0.47897834, 'woody': 0.5456351, 'herbaceous': 0.32628164, 'fatty': 0.5256758}\n",
    "\n",
    "mine_avg = 0\n",
    "MAT_avg = 0\n",
    "for i in mine_pr_dict:\n",
    "    mine_avg += mine_pr_dict[i]\n",
    "    MAT_avg += MAT_pr_dict[i]\n",
    "mine_avg /= 7\n",
    "MAT_avg /= 7\n",
    "print(mine_avg)\n",
    "print(MAT_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine_roc_dict = {'fruity': 0.860701, 'sweet': 0.8052784, 'green': 0.8206578, 'floral': 0.8363286, 'woody': 0.8615828, 'herbaceous': 0.8133802, 'fatty': 0.84928584}\n",
    "MAT_roc_dict = {'fruity': 0.86459976, 'sweet': 0.7982945, 'green': 0.7979386, 'floral': 0.85018015, 'woody': 0.8902269, 'herbaceous': 0.78502715, 'fatty': 0.87442076}\n",
    "\n",
    "mine_avg = 0\n",
    "MAT_avg = 0\n",
    "for i in mine_roc_dict:\n",
    "    mine_avg += mine_roc_dict[i]\n",
    "    MAT_avg += MAT_roc_dict[i]\n",
    "mine_avg /= 7\n",
    "MAT_avg /= 7\n",
    "print(mine_avg)\n",
    "print(MAT_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output\n",
    "out_train = []\n",
    "out_test = []\n",
    "for i in range(test.feature_od):\n",
    "    out_train.append(test.od_train[:, i])\n",
    "    out_test.append(test.od_test[:, i])\n",
    "out_train = tuple(out_train)\n",
    "out_test = tuple(out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine\n",
    "test.use_adj_dist = 'both'\n",
    "model = test.modelBuild2(batch_size=32, num_heads=6, single_attn_dim=30, feedforward_dim=180, num_encoderLayer=3, \n",
    "                    num_decoderLayer=5, dropout_rate=0.1, lr=0.00002, compile=True, normal_init=False, temperature=0.7)\n",
    "\n",
    "model.load_weights('/tf/haha/save_weight/0518/both/6_30_0.7_35/')\n",
    "# model.load_weights('/tf/haha/save_weight/0522/4/')\n",
    "\n",
    "if len(test.test_input) == test.input_items-1:\n",
    "    test.test_input = list(test.test_input)\n",
    "    test.test_input.append(test.od_test)\n",
    "    test.test_input = tuple(test.test_input)\n",
    "\n",
    "preds_mine = model(test.test_input)\n",
    "eva_dict = model.evaluate(test.test_input, out_test, return_dict=True, batch_size=1)\n",
    "# eva_dict['sweet_sweet_precision'] = eva_dict['sweet_precision'] #!!!!\n",
    "# eva_dict['sweet_sweet_recall'] = eva_dict['sweet_recall'] #!!!!\n",
    "print(test.calFscore(eva_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAT\n",
    "test.use_adj_dist = 'MAT'\n",
    "model = test.modelBuild2(batch_size=32, num_heads=6, single_attn_dim=30, feedforward_dim=180, num_encoderLayer=3, \n",
    "                    num_decoderLayer=3, dropout_rate=0.1, lr=0.00002, compile=True, normal_init=False, temperature=0.7)\n",
    "\n",
    "model.load_weights('/tf/haha/save_weight/0519/6_30_0.7_33/')\n",
    "# model.load_weights('/tf/haha/save_weight/0522/4_MAT/')\n",
    "\n",
    "if len(test.test_input) == test.input_items-1:\n",
    "    test.test_input = list(test.test_input)\n",
    "    test.test_input.append(test.od_test)\n",
    "    test.test_input = tuple(test.test_input)\n",
    "\n",
    "preds_MAT = model(test.test_input)\n",
    "eva_dict = model.evaluate(test.test_input, out_test, return_dict=True, batch_size=1)\n",
    "# eva_dict['sweet_sweet_precision'] = eva_dict['sweet_precision'] #!!!!\n",
    "# eva_dict['sweet_sweet_recall'] = eva_dict['sweet_recall'] #!!!!\n",
    "print(test.calFscore(eva_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mine_concat = tf.concat(preds_mine, axis=0)\n",
    "print(preds_mine_concat.shape)\n",
    "out_concat = tf.concat(out_test, axis=0)\n",
    "print(out_concat.shape)\n",
    "preds_MAT_concat = tf.concat(preds_MAT, axis=0)\n",
    "print(preds_MAT_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macroF1(targets, preds):\n",
    "    precision_cal = tf.keras.metrics.Precision()\n",
    "    recall_cal = tf.keras.metrics.Recall()\n",
    "\n",
    "    precision_cal.reset_state()\n",
    "    precision_cal.update_state(targets, preds)\n",
    "    precision = precision_cal.result().numpy()\n",
    "\n",
    "    recall_cal.reset_state()\n",
    "    recall_cal.update_state(targets, preds)\n",
    "    recall = recall_cal.result().numpy()\n",
    "\n",
    "    macro_F1 = (2*precision*recall) / (precision+recall)\n",
    "    return macro_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(preds, rseed):\n",
    "\n",
    "    preds_temp = preds - 0.5\n",
    "    temp = tf.random.uniform(shape=preds.shape, minval=0, maxval=2, dtype=tf.dtypes.int32, seed=rseed)\n",
    "    temp = tf.cast(temp, dtype=tf.float32)\n",
    "    temp -= 0.5\n",
    "    temp *= 2\n",
    "    fliped_preds = preds_temp * temp\n",
    "    fliped_preds += 0.5\n",
    "\n",
    "    return fliped_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mine = macroF1(out_concat, preds_mine_concat)\n",
    "f_MAT = macroF1(out_concat, preds_MAT_concat)\n",
    "print([f_mine, f_MAT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_real = abs(f_mine - f_MAT)\n",
    "repeat = 10000\n",
    "r = 0\n",
    "for i in range(repeat):\n",
    "    fliped_mine = flip(preds_mine_concat, i)\n",
    "    fliped_MAT = flip(preds_MAT_concat, i+1000)\n",
    "\n",
    "    f_mine_fliped = macroF1(out_concat, fliped_mine)\n",
    "    f_MAT_fliped = macroF1(out_concat, fliped_MAT)\n",
    "\n",
    "    t_fliped = abs(f_mine_fliped - f_MAT_fliped)\n",
    "\n",
    "    if t_fliped >= t_real:\n",
    "        r += 1\n",
    "print(r)\n",
    "print((r+1)/(repeat+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for od in range(test.feature_od):\n",
    "    od_n = test.od_name[od]\n",
    "\n",
    "    f_mine = macroF1(out_test[od], preds_mine[od])\n",
    "    f_MAT = macroF1(out_test[od], preds_MAT[od])\n",
    "\n",
    "    t_real = abs(f_mine - f_MAT)\n",
    "    repeat = 10000\n",
    "    r = 0\n",
    "    for i in range(repeat):\n",
    "        fliped_mine = flip(preds_mine[od], i)\n",
    "        fliped_MAT = flip(preds_MAT[od], i+1000)\n",
    "\n",
    "        f_mine_fliped = macroF1(out_test[od], fliped_mine)\n",
    "        f_MAT_fliped = macroF1(out_test[od], fliped_MAT)\n",
    "\n",
    "        t_fliped = abs(f_mine_fliped - f_MAT_fliped)\n",
    "\n",
    "        if t_fliped >= t_real:\n",
    "            r += 1\n",
    "\n",
    "    print('%s: F1_Mine %.3f, F1_MAT %.3f, p %.3f' % (od_n, f_mine, f_MAT, (r+1)/(repeat+1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles(smiles_list[15])\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllChem.EmbedMolecule(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = mol.GetConformer()\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = Chem.rdmolops.FindAllPathsOfLengthN(mol, 4, useBonds=False)\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    path = list(path)\n",
    "    print(path, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.rdMolTransforms.GetDihedralDeg(conf, 4, 3, 6, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.rdMolTransforms.GetDihedralDeg(conf, 7,6,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = Chem.rdmolops.FindAllPathsOfLengthN(mol, 3, useBonds=False)\n",
    "for path in paths:\n",
    "    path = list(path)\n",
    "    print(path, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.rdMolTransforms.GetAngleDeg(conf, 0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.rdMolTransforms.GetAngleDeg(conf, 2,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_angle = []\n",
    "all_torsion = []\n",
    "max_mol = 60\n",
    "for smi in smiles_list[:10]:\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        AllChem.EmbedMolecule(mol)\n",
    "        conf = mol.GetConformer()\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    torsion = np.zeros((max_mol, max_mol))\n",
    "    angle = np.zeros((max_mol, max_mol))\n",
    "\n",
    "    # torsion\n",
    "    paths = Chem.rdmolops.FindAllPathsOfLengthN(mol, 4, useBonds=False)\n",
    "    for path in paths:\n",
    "        path = list(path)\n",
    "        deg = Chem.rdMolTransforms.GetDihedralDeg(conf, path[0], path[1], path[2], path[3])\n",
    "        torsion[path[0]][path[-1]] = deg\n",
    "    torsion = tf.convert_to_tensor(torsion)\n",
    "    torsion = tf.expand_dims(torsion, axis=0)\n",
    "    all_torsion.append(torsion)\n",
    "\n",
    "    # angle\n",
    "    paths = Chem.rdmolops.FindAllPathsOfLengthN(mol, 3, useBonds=False)\n",
    "    for path in paths:\n",
    "        path = list(path)\n",
    "        deg = Chem.rdMolTransforms.GetAngleDeg(conf, path[0], path[1], path[2])\n",
    "        angle[path[0]][path[-1]] = deg\n",
    "    angle = tf.convert_to_tensor(angle)\n",
    "    angle = tf.expand_dims(angle, axis=0)\n",
    "    all_angle.append(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_torsion = tf.concat(all_torsion, axis=0)\n",
    "all_angle = tf.concat(all_angle, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_torsion[7][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# min dist when no bond, max dist when bonded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer2OD_tada\n",
      "transformer2od\n",
      "22 mol cannot compute distance, they are: [1992, 1999, 2005, 2012, 2016, 2018, 2024, 2513, 2565, 3057, 3068, 3260, 3270, 3289, 3329, 3553, 3554, 3650, 3833, 3871, 3883, 3889]\n",
      "num_sample : 3893\n",
      "mask_mat: (3893, 1, 1, 60)\n",
      "mol_atom_feat.shape: (3893, 60, 71)\n",
      "distance value type is: original\n",
      "all_adj.shape = : (3893, 60, 60)\n",
      "all_dist.shape = : (3893, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "test = Haha.Transformer2OD_tada()\n",
    "# test.train_test = (4000,1)\n",
    "all_mol = test.molData_atomicF(smiles_list, dist_value='original', atomH=False, failed_mol=None, rseed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dist_nobond.shape[0]):\n",
    "    for j in range(dist_nobond.shape[1]):\n",
    "        for k in range(dist_nobond.shape[2]):\n",
    "            if dist_nobond[i,j,k] == 0:\n",
    "                print([i,j,k])\n",
    "                break\n",
    "                break\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[   2.004196     1.7499114    1.2353657    1.7961552    1.9992151\n",
      "    1.8109034    1.2766627    1.8064586    1.4563416    3.4511895\n",
      "    3.412709  1000.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.       ], shape=(60,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dist_nobond[154,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3070, 60)\n"
     ]
    }
   ],
   "source": [
    "arg_2 = tf.argmin(dist_nobond, axis=2)\n",
    "print(arg_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1782, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(test.shuffle_index[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.        0.        0.        0.        1.539209  0.        1.4821252\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.       ], shape=(60,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dist_bonded[tf.math.greater_equal(x, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "a = tf.math.greater_equal(dist_bonded, 2.67)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.cast(a, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240, 60)\n",
      "(3240,)\n"
     ]
    }
   ],
   "source": [
    "b = tf.reduce_sum(a, axis=2)\n",
    "print(b.shape)\n",
    "c = tf.reduce_sum(b, axis=1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "for i in range(3070):\n",
    "    if c[i] != 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[1, 0]\n",
      "[3, 4]\n",
      "[4, 3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(60):\n",
    "    for j in range(60):\n",
    "        if dist_bonded[177][i][j] > 2.67:\n",
    "            print([i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.       2.688521 0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.      ], shape=(60,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dist_bonded[177,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1000.        1002.68854      3.0761933    4.0231733    6.074951\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.       ], shape=(60,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dist_nobond[177,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1000.        1001.4904       2.516548     3.582225     3.6575754\n",
      "    2.5988078    3.1296647    3.5104814    4.710173     3.6228151\n",
      "    5.781528     5.47538   1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.\n",
      " 1000.        1000.        1000.        1000.        1000.       ], shape=(60,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dist_nobond[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3777, shape=(), dtype=int32)\n",
      "tf.Tensor(3539, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(test.shuffle_index[177])\n",
    "print(test.shuffle_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "   1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "   1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]], shape=(1, 1, 60), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fb8f29408e0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = all_mol[3777]\n",
    "print(mol.GetNumAtoms())\n",
    "print(mask[177])\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "   1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "   1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]], shape=(1, 1, 60), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fb8f2939e20>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = all_mol[3539]\n",
    "print(mol.GetNumAtoms())\n",
    "print(mask[0])\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "mol = Chem.MolFromSmiles('[NH4+].[SH-]')\n",
    "AllChem.EmbedMolecule(mol)\n",
    "dist_temp = AllChem.Get3DDistanceMatrix(mol)\n",
    "print(dist_temp)\n",
    "adj_temp = AllChem.GetAdjacencyMatrix(mol)\n",
    "print(adj_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom = mol.GetAtomWithIdx(5)\n",
    "atom.GetSymbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 60)\n"
     ]
    }
   ],
   "source": [
    "arg_0 = tf.argmin(dist_nobond, axis=0)\n",
    "print(arg_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=int64, numpy=1437>, 0, 2]\n",
      "tf.Tensor(0.00013606253, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp = 1000\n",
    "for i in range(60):\n",
    "    for j in range(60):\n",
    "        s_ind = arg_0[i,j]\n",
    "        min_d = tf.reduce_min(dist_nobond[s_ind])\n",
    "        if min_d == 0:\n",
    "            continue\n",
    "        \n",
    "        if min_d < temp:\n",
    "            cood = [s_ind,i,j]\n",
    "            temp = min_d\n",
    "print(cood)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2012, shape=(), dtype=int32)\n",
      "12\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAACWCAIAAADCEh9HAAAABmJLR0QA/wD/AP+gvaeTAAADeUlEQVR4nO3cv0rbcRTG4ZPQdFEQXBKvoXoBXoVu6tDsju7Fxc3F0T1d9AKcncTRzVuIIoiCk0PSwVJshxD7kj+S5yFLyBkOCfnwzS8hjeFwWAD8r+asFwD43GQUICKjABEZBYjIKEBERgEiMgoQkVGAiIwCRGQUICKjABEZBYjIKEBERgEiMgoQkVGAiIwCRGQUICKjABEZBYjIKEBERgEiMgoQkVGAiIwCRGQUICKjABEZBYjIKEBERgEiMgoQkVGAiIwCRGQUICKjABEZBYjIKEBERgEiMgoQkVGAiIwCRGQUICKjABEZBYjIKEBERgEiMgoQkVGAiIwCRGQUICKjABEZBYjIKEBERgEiMgoQkVGAiIwCRGQUICKjABEZBYjIKEBERgEiMgoQkVGAiIwCRGQUICKjC+bqqlqtajbHuq2v12Aw643nwGBQ376N+6S1WnV9PeuNmarGcDic9Q5MUadT9/cfmD87q52diW3zSZyf1+7uB+bb7bq7m9g2zJ0vs16A6Xo7XbbbdXIyauz5ufb3q6peX6ex1Zz78yScntbKyqjJg4O6v3eEXzQyupCWlmpvb9TA3d3vjPLe9nZ1OqMGfvyY1irMEddGASIyChCRUYCIa6NUVTUajfd3O1X9qqrqdrs/u92ZrDQ/vlf1qqpqbW3tny/g/dCFchoFCMkoVVXDv/X7b4fR6vV6w4XX670dRqvf7//z0OxeMeaIjAJEZBQgIqMAEd/UL6Snpzo6GjXw8jKtVT6Vk5NaXh418PQ0rVWYIzK6YNrteniox8c6PBxr/uvXCS/0GayuVrNZg0EdH4813/Qhb7H4h6fFs7FRt7djTa6v182NKFRVXVzU1laN82ZpterysjY3J78T80JGASIOGgARGQWIyChAREYBIjIKEJFRgIiMAkRkFCAiowARGQWIyChAREYBIjIKEJFRgIiMAkRkFCAiowARGQWIyChAREYBIjIKEJFRgIiMAkRkFCAiowARGQWIyChAREYBIjIKEJFRgIiMAkRkFCAiowARGQWIyChAREYBIjIKEJFRgIiMAkRkFCAiowARGQWIyChAREYBIjIKEJFRgIiMAkRkFCAiowARGQWIyChAREYBIjIKEJFRgIiMAkRkFCAiowARGQWIyChAREYBIjIKEJFRgIiMAkRkFCAiowARGQWI/AJIjX1KuCyixQAAAIt6VFh0cmRraXRQS0wgcmRraXQgMjAyMS4wOS40AAB4nHu/b+09BiDgZUAAHiBmA+IGRjaGBCDNyEwrmpuBkYGJmYGFlYGNnYGDk4GLm0GEQXwWSA6KGXgWqTnZw1wGZO+HsdXWO9gjseHiV2sc7ZHYcHHD0wj1QDZcXOYFwnwgGy7eq48QB7Lh4mIA0QUeXe6cdUQAAADuelRYdE1PTCByZGtpdCAyMDIxLjA5LjQAAHicjZJLDoIwEIb3PcVcQDPTF2UpjxhjgETRO7j3/nEqlJaYtLYshvL1b+g3Avy4ddfXG7ahOiEAMPPUdQ1PhYhiAF9A058vI7TzqQkr7fQY5zuQBMtbeO7R0zwNYYWgBTxWxmmUXOB3JEXgJHOHf0C1BkpbqRynQ2AJNGugcUQ5zobAElitgYp2n384FwJLYL0EWlJG5zjCNbFMblqMclkweimQ/djtxC+t0ExjF1vBTxmNE8vU0SuxChv1EV+ki5KIr4ESGeR/gmR6fHqYfw8ty7X4AIFMkWKcUZcWAAAAZXpUWHRTTUlMRVMgcmRraXQgMjAyMS4wOS40AAB4nHN21nNGQQo1GgZ65qYWJgZGOgY61rrIHBDbyMzcGC4B44DYphaGhnAJGAfENkYIG8MEzQyNTU1gwnAO2C5TYwuExRCOZg0ARjYh1TMDAgcAAAAASUVORK5CYII=",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fb8f387be20>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shuffle_index[1437])\n",
    "mol = all_mol[2012]\n",
    "print(mol.GetNumAtoms())\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC.CC.CC.CC.CC.CC'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chem.rdmolfiles.MolToSmiles(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1.0000000e+03 1.0015168e+03 5.7294620e-03 1.5110745e+00 2.5909878e-03\n",
      " 1.5142130e+00 5.3015542e-03 1.5115024e+00 2.9522046e-03 1.5197562e+00\n",
      " 1.3606253e-04 1.5169400e+00 1.0000000e+03 1.0000000e+03 1.0000000e+03\n",
      " 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03\n",
      " 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03\n",
      " 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03\n",
      " 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03\n",
      " 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03\n",
      " 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03\n",
      " 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03\n",
      " 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03\n",
      " 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03 1.0000000e+03], shape=(60,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dist_nobond[1437,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.0000000e+00 1.5168040e+00 5.7294620e-03 1.5110745e+00 2.5909878e-03\n",
      " 1.5142130e+00 5.3015542e-03 1.5115024e+00 2.9522046e-03 1.5197562e+00\n",
      " 1.3606253e-04 1.5169400e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], shape=(60,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dist[1437, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=2.688521>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]\n"
     ]
    }
   ],
   "source": [
    "adj = test.train_input[2]\n",
    "dist = test.train_input[3]\n",
    "\n",
    "dist_bonded = dist * adj\n",
    "max_dist_bonded = tf.math.reduce_max(dist_bonded)\n",
    "\n",
    "\n",
    "dist_nobond = dist + (adj*1000)\n",
    "\n",
    "temp = tf.eye(test.max_mol) * 1000\n",
    "dist_nobond += temp[tf.newaxis, :, :]\n",
    "\n",
    "mask = test.train_input[4]\n",
    "mask1 = tf.squeeze(mask)\n",
    "mask1 = mask1 * 1000\n",
    "mask1 = tf.expand_dims(mask1, axis=1)\n",
    "dist_nobond += mask1\n",
    "dist_nobond += tf.transpose(mask1, perm=[0,2,1])\n",
    "\n",
    "min_dist_nobond = tf.math.reduce_min(dist_nobond)\n",
    "\n",
    "print([max_dist_bonded, min_dist_nobond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = test.test_input[2]\n",
    "dist = test.test_input[3]\n",
    "\n",
    "dist_bonded = dist * adj\n",
    "max_dist_bonded = tf.math.reduce_max(dist_bonded)\n",
    "dist_nobond = dist * (-1*adj+1)\n",
    "min_dist_nobond = tf.math.reduce_min(dist_nobond)\n",
    "\n",
    "print([max_dist_bonded, min_dist_nobond])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output\n",
    "out_train = []\n",
    "out_test = []\n",
    "for i in range(test1.feature_od):\n",
    "    out_train.append(test1.od_train[:, i])\n",
    "    out_test.append(test1.od_test[:, i])\n",
    "out_train = tuple(out_train)\n",
    "out_test = tuple(out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = test1.modelBuild2(batch_size=32, num_heads=6, single_attn_dim=30, feedforward_dim=180, num_encoderLayer=2, \n",
    "                    num_decoderLayer=4, dropout_rate=0.1, lr=0.00002, compile=True, normal_init=False, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/tf/haha/save_weight/0520/2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odlist_4 = [\n",
    "    'sweet', #'fruity'\n",
    "]\n",
    "\n",
    "getdata = Haha.BasicData(which_data='Paper')\n",
    "getdata.which_data = 'keller'\n",
    "getdata.readOD(50, od_selected=odlist_4, filelist=['keller.txt'])\n",
    "smiles_list = getdata.readSmiles(filelist=['keller.txt'])\n",
    "print(len(smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = Haha.Transformer2OD_tada()\n",
    "test1.train_test = (1,476)\n",
    "test1.molData_atomicF(smiles_list, dist_value='exp', atomH=False, failed_mol=None)\n",
    "test1.odData(getdata.od_mat_ori, getdata.od_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(test1.test_input) == test1.input_items-1:\n",
    "    test1.test_input = list(test1.test_input)\n",
    "    test1.test_input.append(test1.od_test)\n",
    "    test1.test_input = tuple(test1.test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(test1.test_input)\n",
    "# del pred\n",
    "eva_dict = model.evaluate(test1.test_input, out_test, return_dict=True, batch_size=1)\n",
    "print(test1.calFscore(eva_dict))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
