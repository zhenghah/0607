{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mainCode as Haha\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic data (ODs prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all type odor descriptors = 1615\n",
      "appear times >= 50 odor descriptors have 98\n",
      "they are\n",
      "['fruity', 'sweet', 'green', 'floral', 'woody', 'herbaceous', 'fresh', 'fatty', 'spicy', 'waxy', 'citrus', 'rose', 'nutty', 'oily', 'earthy', 'balsam', 'berry', 'tropical', 'sulfurous', 'aromatic', 'vegetable', 'apple', 'minty', 'powdery', 'roasted', 'meaty', 'pineapple', 'creamy', 'aldehydic', 'ethereal', 'musty', 'phenolic', 'leafy', 'honey', 'caramel', 'camphor', 'pungent', 'metallic', 'orange', 'winey', 'pear', 'melon', 'natural', 'banana', 'amber', 'buttery', 'jasmin', 'onion', 'cheese', 'musk', 'animal', 'coffee', 'lemon', 'coconut', 'pine', 'burnt', 'vanilla', 'peach', 'mushroom', 'tobacco', 'apricot', 'cooling', 'cocoa', 'garlic', 'violet', 'cherry', 'cinnamon', 'almond', 'grape', 'anise', 'medicinal', 'rum', 'chocolate', 'milky', 'dairy', 'alliaceous', 'grassy', 'lily', 'cooked', 'hyacinth', 'geranium', 'grapefruit', 'plum', 'terpene', 'skin', 'cedar', 'pepper', 'leather', 'lavender', 'orris', 'soapy', 'lactonic', 'savory', 'muguet', 'hay', 'smoky', 'cucumber', 'alcoholic']\n",
      "final od_times with all samples: {'fruity': 1334, 'sweet': 1183, 'green': 1116, 'floral': 907, 'woody': 694, 'herbaceous': 585, 'fresh': 576, 'fatty': 431, 'spicy': 411, 'waxy': 404, 'citrus': 341, 'rose': 335, 'nutty': 291, 'oily': 288, 'earthy': 275, 'balsam': 268, 'berry': 245, 'tropical': 241, 'sulfurous': 216, 'aromatic': 212, 'vegetable': 210, 'apple': 200, 'minty': 199, 'powdery': 196, 'roasted': 183, 'meaty': 176, 'pineapple': 176, 'creamy': 167, 'aldehydic': 166, 'ethereal': 162, 'musty': 160, 'phenolic': 157, 'leafy': 153, 'honey': 144, 'caramel': 140, 'camphor': 140, 'pungent': 133, 'metallic': 130, 'orange': 127, 'winey': 126, 'pear': 124, 'melon': 120, 'natural': 118, 'banana': 114, 'amber': 113, 'buttery': 107, 'jasmin': 107, 'onion': 105, 'cheese': 103, 'musk': 102, 'animal': 98, 'coffee': 97, 'lemon': 96, 'coconut': 95, 'pine': 90, 'burnt': 89, 'vanilla': 88, 'peach': 88, 'mushroom': 86, 'tobacco': 82, 'apricot': 80, 'cooling': 79, 'cocoa': 78, 'garlic': 78, 'violet': 78, 'cherry': 77, 'cinnamon': 76, 'almond': 75, 'grape': 73, 'anise': 71, 'medicinal': 70, 'rum': 70, 'chocolate': 69, 'milky': 68, 'dairy': 68, 'alliaceous': 67, 'grassy': 66, 'lily': 66, 'cooked': 65, 'hyacinth': 65, 'geranium': 63, 'grapefruit': 63, 'plum': 61, 'terpene': 60, 'skin': 60, 'cedar': 59, 'pepper': 58, 'leather': 57, 'lavender': 57, 'orris': 57, 'soapy': 56, 'lactonic': 55, 'savory': 53, 'muguet': 53, 'hay': 53, 'smoky': 51, 'cucumber': 51, 'alcoholic': 50}\n",
      "4240\n",
      "222\n",
      "4462\n",
      "4462\n"
     ]
    }
   ],
   "source": [
    "getdata = Haha.BasicData(which_data='mine')\n",
    "getdata.readOD(50, od_selected=None, filelist=['webScrapping/tgsc_odorant_1020.txt'], keep_odStr=True)\n",
    "smiles_list = getdata.readSmiles(filelist=['webScrapping/tgsc_odorant_1020.txt'])\n",
    "print(len(smiles_list))\n",
    "\n",
    "getdata.which_data = 'odorless'\n",
    "smiles_list_odorless = getdata.readSmiles(filelist=['webScrapping/tgsc_odorless_1020.txt']) \n",
    "print(len(smiles_list_odorless))\n",
    "\n",
    "smiles_list.extend(smiles_list_odorless)\n",
    "print(len(smiles_list))\n",
    "temp = (len(smiles_list)-len(getdata.all_odStr)) * ['odorless']\n",
    "getdata.all_odStr.extend(temp)\n",
    "print(len(getdata.all_odStr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODs prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer2OD_tada\n",
      "transformer2od\n",
      "97 mol cannot compute distance, they are: [0, 13, 39, 87, 140, 643, 644, 741, 757, 766, 774, 785, 791, 804, 839, 842, 902, 908, 1184, 1328, 1342, 1345, 1346, 1379, 1529, 1530, 1781, 1868, 1887, 2067, 2078, 2080, 2216, 2222, 2233, 2240, 2246, 2256, 2262, 2264, 2270, 2439, 2444, 2493, 2505, 2601, 2622, 2664, 2692, 2713, 2763, 2767, 2775, 2822, 2844, 2859, 2868, 2873, 2897, 2961, 2988, 3107, 3437, 3511, 3522, 3565, 3736, 3746, 3765, 3805, 3865, 3881, 3921, 3995, 4082, 4083, 4153, 4199, 4202, 4204, 4246, 4254, 4267, 4268, 4272, 4297, 4299, 4303, 4304, 4357, 4383, 4418, 4419, 4421, 4431, 4436, 4451]\n",
      "num_sample : 4365\n",
      "mask_mat: (4365, 1, 1, 60)\n",
      "mol_atom_feat.shape: (4365, 60, 71)\n",
      "distance value type is: exp\n",
      "all_adj.shape = : (4365, 60, 60)\n",
      "all_dist.shape = : (4365, 60, 60)\n",
      "od_shuffled.shape =  (4365, 98)\n",
      "positive sample distribution in test set:\n",
      "{'fruity': 242.0, 'sweet': 208.0, 'green': 189.0, 'floral': 147.0, 'woody': 107.0, 'herbaceous': 101.0, 'fresh': 104.0, 'fatty': 78.0, 'spicy': 68.0, 'waxy': 63.0, 'citrus': 59.0, 'rose': 53.0, 'nutty': 58.0, 'oily': 53.0, 'earthy': 42.0, 'balsam': 38.0, 'berry': 57.0, 'tropical': 43.0, 'sulfurous': 43.0, 'aromatic': 39.0, 'vegetable': 40.0, 'apple': 31.0, 'minty': 32.0, 'powdery': 34.0, 'roasted': 36.0, 'meaty': 36.0, 'pineapple': 28.0, 'creamy': 33.0, 'aldehydic': 22.0, 'ethereal': 29.0, 'musty': 23.0, 'phenolic': 24.0, 'leafy': 30.0, 'honey': 26.0, 'caramel': 33.0, 'camphor': 22.0, 'pungent': 17.0, 'metallic': 20.0, 'orange': 29.0, 'winey': 27.0, 'pear': 28.0, 'melon': 34.0, 'natural': 24.0, 'banana': 21.0, 'amber': 19.0, 'buttery': 18.0, 'jasmin': 9.0, 'onion': 15.0, 'cheese': 23.0, 'musk': 11.0, 'animal': 14.0, 'coffee': 18.0, 'lemon': 19.0, 'coconut': 18.0, 'pine': 13.0, 'burnt': 14.0, 'vanilla': 15.0, 'peach': 11.0, 'mushroom': 13.0, 'tobacco': 11.0, 'apricot': 9.0, 'cooling': 14.0, 'cocoa': 16.0, 'garlic': 11.0, 'violet': 12.0, 'cherry': 16.0, 'cinnamon': 15.0, 'almond': 14.0, 'grape': 21.0, 'anise': 13.0, 'medicinal': 10.0, 'rum': 13.0, 'chocolate': 14.0, 'milky': 11.0, 'dairy': 15.0, 'alliaceous': 10.0, 'grassy': 11.0, 'lily': 8.0, 'cooked': 9.0, 'hyacinth': 14.0, 'geranium': 9.0, 'grapefruit': 10.0, 'plum': 9.0, 'terpene': 9.0, 'skin': 11.0, 'cedar': 10.0, 'pepper': 12.0, 'leather': 10.0, 'lavender': 12.0, 'orris': 9.0, 'soapy': 4.0, 'lactonic': 9.0, 'savory': 6.0, 'muguet': 9.0, 'hay': 7.0, 'smoky': 14.0, 'cucumber': 11.0, 'alcoholic': 9.0}\n",
      "positive sample distribution in train set:\n",
      "{'fruity': 1087.0, 'sweet': 961.0, 'green': 913.0, 'floral': 759.0, 'woody': 569.0, 'herbaceous': 472.0, 'fresh': 463.0, 'fatty': 349.0, 'spicy': 333.0, 'waxy': 338.0, 'citrus': 275.0, 'rose': 282.0, 'nutty': 232.0, 'oily': 233.0, 'earthy': 228.0, 'balsam': 222.0, 'berry': 185.0, 'tropical': 197.0, 'sulfurous': 172.0, 'aromatic': 171.0, 'vegetable': 168.0, 'apple': 169.0, 'minty': 152.0, 'powdery': 161.0, 'roasted': 145.0, 'meaty': 139.0, 'pineapple': 148.0, 'creamy': 133.0, 'aldehydic': 142.0, 'ethereal': 133.0, 'musty': 136.0, 'phenolic': 133.0, 'leafy': 120.0, 'honey': 118.0, 'caramel': 104.0, 'camphor': 109.0, 'pungent': 115.0, 'metallic': 108.0, 'orange': 98.0, 'winey': 97.0, 'pear': 96.0, 'melon': 86.0, 'natural': 93.0, 'banana': 93.0, 'amber': 92.0, 'buttery': 89.0, 'jasmin': 98.0, 'onion': 89.0, 'cheese': 80.0, 'musk': 90.0, 'animal': 83.0, 'coffee': 78.0, 'lemon': 77.0, 'coconut': 77.0, 'pine': 69.0, 'burnt': 75.0, 'vanilla': 71.0, 'peach': 77.0, 'mushroom': 73.0, 'tobacco': 70.0, 'apricot': 71.0, 'cooling': 61.0, 'cocoa': 62.0, 'garlic': 66.0, 'violet': 66.0, 'cherry': 61.0, 'cinnamon': 61.0, 'almond': 61.0, 'grape': 52.0, 'anise': 58.0, 'medicinal': 58.0, 'rum': 57.0, 'chocolate': 55.0, 'milky': 56.0, 'dairy': 53.0, 'alliaceous': 56.0, 'grassy': 54.0, 'lily': 58.0, 'cooked': 56.0, 'hyacinth': 50.0, 'geranium': 54.0, 'grapefruit': 52.0, 'plum': 52.0, 'terpene': 48.0, 'skin': 49.0, 'cedar': 48.0, 'pepper': 44.0, 'leather': 47.0, 'lavender': 45.0, 'orris': 48.0, 'soapy': 51.0, 'lactonic': 46.0, 'savory': 46.0, 'muguet': 44.0, 'hay': 43.0, 'smoky': 36.0, 'cucumber': 40.0, 'alcoholic': 40.0}\n"
     ]
    }
   ],
   "source": [
    "test = Haha.Transformer2OD_tada()\n",
    "test.molData_atomicF(smiles_list, dist_value='exp', atomH=False, failed_mol=None, rseed=1)\n",
    "test.odData(getdata.od_mat_ori, getdata.od_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "hpara = {\n",
    "            'num_heads': 8,\n",
    "            'single_attn_dim': 30,\n",
    "            'num_encoderLayer': 7,\n",
    "            'num_decoderLayer': 2, \n",
    "            'learning_rate': 0.00002, \n",
    "            'temperature': 0.7\n",
    "        }\n",
    "\n",
    "record_dir='/tf/haha/code/logs/1114/od98-8_30_72'\n",
    "\n",
    "weight_path = '/tf/haha/save_weight/1114/od98-8_30_72/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/haha/code/logs/1114/od98-8_30_72\n",
      "modelBuild2-temperature 0.700000\n",
      "(3635, 1, 1)\n",
      "(3635, 60, 71)\n",
      "(3635, 60, 60)\n",
      "(3635, 60, 60)\n",
      "(3635, 1, 1, 60)\n",
      "(3635, 98)\n",
      "samples_weight using: fruity: pos2.344 neg1.000   samples_weight using: sweet: pos2.783 neg1.000   samples_weight using: green: pos2.981 neg1.000   samples_weight using: floral: pos3.789 neg1.000   samples_weight using: woody: pos5.388 neg1.000   samples_weight using: herbaceous: pos6.701 neg1.000   samples_weight using: fresh: pos6.851 neg1.000   samples_weight using: fatty: pos9.415 neg1.000   samples_weight using: spicy: pos9.916 neg1.000   samples_weight using: waxy: pos9.754 neg1.000   samples_weight using: citrus: pos12.218 neg1.000   samples_weight using: rose: pos11.890 neg1.000   samples_weight using: nutty: pos14.668 neg1.000   samples_weight using: oily: pos14.601 neg1.000   samples_weight using: earthy: pos14.943 neg1.000   samples_weight using: balsam: pos15.374 neg1.000   samples_weight using: berry: pos18.649 neg1.000   samples_weight using: tropical: pos17.452 neg1.000   samples_weight using: sulfurous: pos20.134 neg1.000   samples_weight using: aromatic: pos20.257 neg1.000   samples_weight using: vegetable: pos20.637 neg1.000   samples_weight using: apple: pos20.509 neg1.000   samples_weight using: minty: pos22.914 neg1.000   samples_weight using: powdery: pos21.578 neg1.000   samples_weight using: roasted: pos24.069 neg1.000   samples_weight using: meaty: pos25.151 neg1.000   samples_weight using: pineapple: pos23.561 neg1.000   samples_weight using: creamy: pos26.331 neg1.000   samples_weight using: aldehydic: pos24.599 neg1.000   samples_weight using: ethereal: pos26.331 neg1.000   samples_weight using: musty: pos25.728 neg1.000   samples_weight using: phenolic: pos26.331 neg1.000   samples_weight using: leafy: pos29.292 neg1.000   samples_weight using: honey: pos29.805 neg1.000   samples_weight using: caramel: pos33.952 neg1.000   samples_weight using: camphor: pos32.349 neg1.000   samples_weight using: pungent: pos30.609 neg1.000   samples_weight using: metallic: pos32.657 neg1.000   samples_weight using: orange: pos36.092 neg1.000   samples_weight using: winey: pos36.474 neg1.000   samples_weight using: pear: pos36.865 neg1.000   samples_weight using: melon: pos41.267 neg1.000   samples_weight using: natural: pos38.086 neg1.000   samples_weight using: banana: pos38.086 neg1.000   samples_weight using: amber: pos38.511 neg1.000   samples_weight using: buttery: pos39.843 neg1.000   samples_weight using: jasmin: pos36.092 neg1.000   samples_weight using: onion: pos39.843 neg1.000   samples_weight using: cheese: pos44.438 neg1.000   samples_weight using: musk: pos39.389 neg1.000   samples_weight using: animal: pos42.795 neg1.000   samples_weight using: coffee: pos45.603 neg1.000   samples_weight using: lemon: pos46.208 neg1.000   samples_weight using: coconut: pos46.208 neg1.000   samples_weight using: pine: pos51.681 neg1.000   samples_weight using: burnt: pos47.467 neg1.000   samples_weight using: vanilla: pos50.197 neg1.000   samples_weight using: peach: pos46.208 neg1.000   samples_weight using: mushroom: pos48.795 neg1.000   samples_weight using: tobacco: pos50.929 neg1.000   samples_weight using: apricot: pos50.197 neg1.000   samples_weight using: cooling: pos58.590 neg1.000   samples_weight using: cocoa: pos57.629 neg1.000   samples_weight using: garlic: pos54.076 neg1.000   samples_weight using: violet: pos54.076 neg1.000   samples_weight using: cherry: pos58.590 neg1.000   samples_weight using: cinnamon: pos58.590 neg1.000   samples_weight using: almond: pos58.590 neg1.000   samples_weight using: grape: pos68.904 neg1.000   samples_weight using: anise: pos61.672 neg1.000   samples_weight using: medicinal: pos61.672 neg1.000   samples_weight using: rum: pos62.772 neg1.000   samples_weight using: chocolate: pos65.091 neg1.000   samples_weight using: milky: pos63.911 neg1.000   samples_weight using: dairy: pos67.585 neg1.000   samples_weight using: alliaceous: pos63.911 neg1.000   samples_weight using: grassy: pos66.315 neg1.000   samples_weight using: lily: pos61.672 neg1.000   samples_weight using: cooked: pos63.911 neg1.000   samples_weight using: hyacinth: pos71.700 neg1.000   samples_weight using: geranium: pos66.315 neg1.000   samples_weight using: grapefruit: pos68.904 neg1.000   samples_weight using: plum: pos68.904 neg1.000   samples_weight using: terpene: pos74.729 neg1.000   samples_weight using: skin: pos73.184 neg1.000   samples_weight using: cedar: pos74.729 neg1.000   samples_weight using: pepper: pos81.614 neg1.000   samples_weight using: leather: pos76.340 neg1.000   samples_weight using: lavender: pos79.778 neg1.000   samples_weight using: orris: pos74.729 neg1.000   samples_weight using: soapy: pos70.275 neg1.000   samples_weight using: lactonic: pos78.022 neg1.000   samples_weight using: savory: pos78.022 neg1.000   samples_weight using: muguet: pos81.614 neg1.000   samples_weight using: hay: pos83.535 neg1.000   samples_weight using: smoky: pos99.972 neg1.000   samples_weight using: cucumber: pos89.875 neg1.000   samples_weight using: alcoholic: pos89.875 neg1.000   0 WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (19, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (19, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (19, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (19, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\"), but it was called on an input with incompatible shape (19, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 98) for input KerasTensor(type_spec=TensorSpec(shape=(32, 98), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\"), but it was called on an input with incompatible shape (19, 98).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (26, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (26, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (26, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (26, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\"), but it was called on an input with incompatible shape (26, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 98) for input KerasTensor(type_spec=TensorSpec(shape=(32, 98), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\"), but it was called on an input with incompatible shape (26, 98).\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 weight保存开始：Mon Nov 14 06:34:51 2022 weight保存完成 Mon Nov 14 06:34:53 2022\n",
      "57 weight保存开始：Mon Nov 14 06:35:38 2022 weight保存完成 Mon Nov 14 06:35:40 2022\n",
      "58 weight保存开始：Mon Nov 14 06:36:25 2022 weight保存完成 Mon Nov 14 06:36:32 2022\n",
      "59 weight保存开始：Mon Nov 14 06:37:17 2022 weight保存完成 Mon Nov 14 06:37:19 2022\n",
      "60 61 weight保存开始：Mon Nov 14 06:38:48 2022 weight保存完成 Mon Nov 14 06:38:50 2022\n",
      "62 weight保存开始：Mon Nov 14 06:39:35 2022 weight保存完成 Mon Nov 14 06:39:37 2022\n",
      "63 64 65 weight保存开始：Mon Nov 14 06:41:50 2022 weight保存完成 Mon Nov 14 06:41:52 2022\n",
      "66 67 weight保存开始：Mon Nov 14 06:43:22 2022 weight保存完成 Mon Nov 14 06:43:24 2022\n",
      "68 weight保存开始：Mon Nov 14 06:44:08 2022 weight保存完成 Mon Nov 14 06:44:10 2022\n",
      "69 weight保存开始：Mon Nov 14 06:44:55 2022 weight保存完成 Mon Nov 14 06:44:57 2022\n",
      "70 71 72 weight保存开始：Mon Nov 14 06:47:11 2022 weight保存完成 Mon Nov 14 06:47:13 2022\n",
      "73 weight保存开始：Mon Nov 14 06:47:57 2022 weight保存完成 Mon Nov 14 06:47:59 2022\n",
      "74 weight保存开始：Mon Nov 14 06:48:44 2022 weight保存完成 Mon Nov 14 06:48:46 2022\n",
      "75 76 77 78 79 weight保存开始：Mon Nov 14 06:52:31 2022 weight保存完成 Mon Nov 14 06:52:33 2022\n",
      "80 weight保存开始：Mon Nov 14 06:53:17 2022 weight保存完成 Mon Nov 14 06:53:19 2022\n",
      "81 weight保存开始：Mon Nov 14 06:54:04 2022 weight保存完成 Mon Nov 14 06:54:06 2022\n",
      "82 weight保存开始：Mon Nov 14 06:54:50 2022 weight保存完成 Mon Nov 14 06:54:52 2022\n",
      "83 84 85 86 87 88 89 90 weight保存开始：Mon Nov 14 07:00:50 2022 weight保存完成 Mon Nov 14 07:00:52 2022\n",
      "91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 {'avg': 0.33147895063370353, 'avg_pcs': 0.30393450669184024, 'avg_rc': 0.38927873991885964, 'fruity': 0.6525096304239195, 'sweet': 0.5200845580370965, 'green': 0.5278450335554951, 'floral': 0.5400593576167682, 'woody': 0.5315315162179609, 'herbaceous': 0.4147465461205074, 'fresh': 0.3465346586890062, 'fatty': 0.4733727955253869, 'spicy': 0.3821656122217894, 'waxy': 0.46153846882544874, 'citrus': 0.45901639213711937, 'rose': 0.5196850390522662, 'nutty': 0.46428572051987355, 'oily': 0.24000000161528587, 'earthy': 0.26086956737228484, 'balsam': 0.4646464674135407, 'berry': 0.25531914559706875, 'tropical': 0.37362637243154534, 'sulfurous': 0.7173912948691098, 'aromatic': 0.12345679368011246, 'vegetable': 0.3218390746087659, 'apple': 0.382022482159011, 'minty': 0.43835615521189536, 'powdery': 0.21739131015054666, 'roasted': 0.49315068906994153, 'meaty': 0.5789473720534685, 'pineapple': 0.4242424211226219, 'creamy': 0.32911392287592167, 'aldehydic': 0.43750000599538885, 'ethereal': 0.5194805152582304, 'musty': 0.13636363856494416, 'phenolic': 0.5714285787270993, 'leafy': 0.24000000596046445, 'honey': 0.4347826130899454, 'caramel': 0.4935064924006558, 'camphor': 0.3773584886563122, 'pungent': 0.18181818865547494, 'metallic': 0.07407407575019918, 'orange': 0.5245901630053562, 'winey': 0.18181818109898512, 'pear': 0.3703703781377795, 'melon': 0.47058823704719543, 'natural': 0.07407407628165351, 'banana': 0.29629630383885935, 'amber': 0.37209303067012883, 'buttery': 0.2500000094622373, 'jasmin': 0.3333333387970923, 'onion': 0.42857143298095585, 'cheese': 0.40000000181276935, 'musk': 0.47619048362416194, 'animal': 0.4000000105857849, 'coffee': 0.4090909154947138, 'lemon': 0.3555555643270044, 'coconut': 0.5365853665628154, 'pine': 0.3255814013447613, 'burnt': 0.2857142889499664, 'vanilla': 0.3636363692089051, 'peach': 0.22857143538338798, 'mushroom': 0.33333333181562247, 'tobacco': 0.18750000742147677, 'apricot': 0.15789474184699667, 'cooling': 0.19354839060110554, 'cocoa': 0.3225806498130575, 'garlic': 0.3333333446126845, 'violet': 0.2777777711550395, 'cherry': 0.31111110726992286, 'cinnamon': 0.41860465335484875, 'almond': 0.2352941240406366, 'grape': 0.2702702707274279, 'anise': 0.38709678169839956, 'medicinal': 0.25806452062574065, 'rum': 0.38709678169839956, 'chocolate': 0.2307692320036465, 'milky': 0.31250000381260173, 'dairy': 0.2666666805744171, 'alliaceous': 0.37500000931322564, 'grassy': 0.2608695689356394, 'lily': 0.272727274451374, 'cooked': 0.11764705928757942, 'hyacinth': 0.4000000071525573, 'geranium': 0.27586207243832056, 'grapefruit': 0.1176470620203183, 'plum': 0.16000000042915344, 'terpene': 0.5714285787270993, 'skin': 0, 'cedar': 0.3333333406919313, 'pepper': 0, 'leather': 0.15384615472787935, 'lavender': 0.3076923193310845, 'orris': 0.3333333451300858, 'soapy': 0, 'lactonic': 0.3750000004656612, 'savory': 0.13333333551883697, 'muguet': 0.25000000512227416, 'hay': 0, 'smoky': 0.0800000030517578, 'cucumber': 0.42105263744034593, 'alcoholic': 0.20000000394880768}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x7fdc49c3df40>,\n",
       " {'avg': 0.33147895063370353,\n",
       "  'avg_pcs': 0.30393450669184024,\n",
       "  'avg_rc': 0.38927873991885964,\n",
       "  'fruity': 0.6525096304239195,\n",
       "  'sweet': 0.5200845580370965,\n",
       "  'green': 0.5278450335554951,\n",
       "  'floral': 0.5400593576167682,\n",
       "  'woody': 0.5315315162179609,\n",
       "  'herbaceous': 0.4147465461205074,\n",
       "  'fresh': 0.3465346586890062,\n",
       "  'fatty': 0.4733727955253869,\n",
       "  'spicy': 0.3821656122217894,\n",
       "  'waxy': 0.46153846882544874,\n",
       "  'citrus': 0.45901639213711937,\n",
       "  'rose': 0.5196850390522662,\n",
       "  'nutty': 0.46428572051987355,\n",
       "  'oily': 0.24000000161528587,\n",
       "  'earthy': 0.26086956737228484,\n",
       "  'balsam': 0.4646464674135407,\n",
       "  'berry': 0.25531914559706875,\n",
       "  'tropical': 0.37362637243154534,\n",
       "  'sulfurous': 0.7173912948691098,\n",
       "  'aromatic': 0.12345679368011246,\n",
       "  'vegetable': 0.3218390746087659,\n",
       "  'apple': 0.382022482159011,\n",
       "  'minty': 0.43835615521189536,\n",
       "  'powdery': 0.21739131015054666,\n",
       "  'roasted': 0.49315068906994153,\n",
       "  'meaty': 0.5789473720534685,\n",
       "  'pineapple': 0.4242424211226219,\n",
       "  'creamy': 0.32911392287592167,\n",
       "  'aldehydic': 0.43750000599538885,\n",
       "  'ethereal': 0.5194805152582304,\n",
       "  'musty': 0.13636363856494416,\n",
       "  'phenolic': 0.5714285787270993,\n",
       "  'leafy': 0.24000000596046445,\n",
       "  'honey': 0.4347826130899454,\n",
       "  'caramel': 0.4935064924006558,\n",
       "  'camphor': 0.3773584886563122,\n",
       "  'pungent': 0.18181818865547494,\n",
       "  'metallic': 0.07407407575019918,\n",
       "  'orange': 0.5245901630053562,\n",
       "  'winey': 0.18181818109898512,\n",
       "  'pear': 0.3703703781377795,\n",
       "  'melon': 0.47058823704719543,\n",
       "  'natural': 0.07407407628165351,\n",
       "  'banana': 0.29629630383885935,\n",
       "  'amber': 0.37209303067012883,\n",
       "  'buttery': 0.2500000094622373,\n",
       "  'jasmin': 0.3333333387970923,\n",
       "  'onion': 0.42857143298095585,\n",
       "  'cheese': 0.40000000181276935,\n",
       "  'musk': 0.47619048362416194,\n",
       "  'animal': 0.4000000105857849,\n",
       "  'coffee': 0.4090909154947138,\n",
       "  'lemon': 0.3555555643270044,\n",
       "  'coconut': 0.5365853665628154,\n",
       "  'pine': 0.3255814013447613,\n",
       "  'burnt': 0.2857142889499664,\n",
       "  'vanilla': 0.3636363692089051,\n",
       "  'peach': 0.22857143538338798,\n",
       "  'mushroom': 0.33333333181562247,\n",
       "  'tobacco': 0.18750000742147677,\n",
       "  'apricot': 0.15789474184699667,\n",
       "  'cooling': 0.19354839060110554,\n",
       "  'cocoa': 0.3225806498130575,\n",
       "  'garlic': 0.3333333446126845,\n",
       "  'violet': 0.2777777711550395,\n",
       "  'cherry': 0.31111110726992286,\n",
       "  'cinnamon': 0.41860465335484875,\n",
       "  'almond': 0.2352941240406366,\n",
       "  'grape': 0.2702702707274279,\n",
       "  'anise': 0.38709678169839956,\n",
       "  'medicinal': 0.25806452062574065,\n",
       "  'rum': 0.38709678169839956,\n",
       "  'chocolate': 0.2307692320036465,\n",
       "  'milky': 0.31250000381260173,\n",
       "  'dairy': 0.2666666805744171,\n",
       "  'alliaceous': 0.37500000931322564,\n",
       "  'grassy': 0.2608695689356394,\n",
       "  'lily': 0.272727274451374,\n",
       "  'cooked': 0.11764705928757942,\n",
       "  'hyacinth': 0.4000000071525573,\n",
       "  'geranium': 0.27586207243832056,\n",
       "  'grapefruit': 0.1176470620203183,\n",
       "  'plum': 0.16000000042915344,\n",
       "  'terpene': 0.5714285787270993,\n",
       "  'skin': 0,\n",
       "  'cedar': 0.3333333406919313,\n",
       "  'pepper': 0,\n",
       "  'leather': 0.15384615472787935,\n",
       "  'lavender': 0.3076923193310845,\n",
       "  'orris': 0.3333333451300858,\n",
       "  'soapy': 0,\n",
       "  'lactonic': 0.3750000004656612,\n",
       "  'savory': 0.13333333551883697,\n",
       "  'muguet': 0.25000000512227416,\n",
       "  'hay': 0,\n",
       "  'smoky': 0.0800000030517578,\n",
       "  'cucumber': 0.42105263744034593,\n",
       "  'alcoholic': 0.20000000394880768})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample_weight = True\n",
    "test.modelTrain2(hpara, epochs=150, batch_size=32, record_dir=record_dir, save_threshold=0.3, save_path=weight_path, normal_init=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic data (substructure prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "# chembl 推测子结构\n",
    "getdata = Haha.BasicData(which_data=None)\n",
    "smiles_list = getdata.readSmiles(filelist=['webScrapping/chembl_smi.txt'])\n",
    "print(len(smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# substructure prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single substructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dict = {\n",
    "    '0': 'cCc',\n",
    "    '1': 'CC(C)(C)C',\n",
    "    '2': 'CC(C)C', \n",
    "    '3': 'C1=CCCC1', \n",
    "    '4': 'C12CC(CC1)CC2',\n",
    "    '5': '[A,a]C([A,a])([A,a])[A,a]',\n",
    "    '6': '[r5]',\n",
    "    '7': '[r4]',\n",
    "    '8': 'C(=O)O',\n",
    "    '9': 'C(=O)N',\n",
    "    '10': 'CNC',\n",
    "    '11': 'COOC',\n",
    "}\n",
    "\n",
    "od_name_basic = []\n",
    "for i in sub_dict:\n",
    "    od_name_basic.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making inputs and part of outputs(single substructures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer2sub\n",
      "Transformer2OD_tada\n",
      "transformer2od\n",
      "1676 mol cannot compute distance, they are: [6, 79, 134, 141, 205, 220, 353, 382, 447, 520, 636, 741, 746, 767, 787, 835, 839, 850, 918, 958, 991, 1039, 1064, 1101, 1127, 1168, 1193, 1237, 1248, 1252, 1277, 1496, 1500, 1517, 1526, 1574, 1584, 1610, 1630, 1659, 1675, 1815, 1831, 1839, 1872, 2031, 2146, 2198, 2233, 2268, 2521, 2592, 2703, 2728, 2756, 2826, 2887, 2940, 2993, 3045, 3128, 3141, 3170, 3178, 3202, 3291, 3310, 3457, 3489, 3529, 3652, 3720, 3779, 3800, 3809, 3818, 3923, 3998, 4033, 4119, 4149, 4153, 4183, 4227, 4327, 4428, 4429, 4475, 4515, 4603, 4697, 4745, 4748, 4762, 4842, 4846, 4852, 4907, 4931, 4976, 5067, 5314, 5346, 5398, 5428, 5434, 5461, 5582, 5636, 5649, 5671, 5738, 5806, 5894, 5961, 6111, 6169, 6176, 6249, 6296, 6361, 6379, 6416, 6439, 6529, 6675, 6686, 6687, 6696, 6927, 6970, 7033, 7109, 7126, 7198, 7226, 7262, 7295, 7318, 7351, 7404, 7439, 7478, 7556, 7561, 7591, 7631, 7672, 7686, 7714, 7890, 7949, 7955, 7978, 8177, 8185, 8240, 8257, 8278, 8289, 8427, 8516, 8668, 8732, 8867, 8874, 8941, 8980, 9253, 9258, 9272, 9310, 9366, 9467, 9594, 9639, 9710, 9928, 9940, 9964, 10103, 10124, 10355, 10407, 10470, 10599, 10602, 10638, 10664, 10705, 10765, 10815, 10851, 11031, 11043, 11119, 11142, 11246, 11279, 11280, 11354, 11390, 11396, 11484, 11554, 11591, 11621, 11752, 11802, 11975, 11977, 12042, 12089, 12129, 12214, 12244, 12252, 12318, 12350, 12440, 12466, 12475, 12542, 12603, 12708, 12938, 13221, 13231, 13400, 13490, 13506, 13668, 13706, 13765, 13775, 13916, 14060, 14191, 14203, 14469, 14495, 14539, 14555, 14604, 14804, 14843, 14848, 14897, 15080, 15111, 15137, 15211, 15279, 15350, 15378, 15397, 15416, 15425, 15458, 15560, 15656, 15808, 15841, 15907, 15918, 15983, 16125, 16144, 16256, 16404, 16440, 16460, 16594, 16621, 16827, 17081, 17175, 17227, 17495, 17551, 17578, 17633, 17655, 17685, 17689, 17726, 17812, 17901, 17902, 17950, 17964, 18046, 18050, 18106, 18111, 18112, 18137, 18186, 18204, 18461, 18534, 18542, 18558, 18628, 18720, 18845, 19105, 19169, 19210, 19238, 19254, 19289, 19301, 19305, 19324, 19344, 19349, 19449, 19478, 19707, 19764, 19780, 19961, 20024, 20142, 20190, 20213, 20224, 20311, 20432, 20463, 20490, 20500, 20747, 20842, 20900, 21106, 21119, 21167, 21231, 21239, 21384, 21462, 21530, 21593, 21642, 21724, 21837, 21851, 21874, 22061, 22104, 22172, 22327, 22336, 22407, 22420, 22558, 22574, 22593, 22601, 22629, 22725, 22782, 22817, 22837, 22935, 22941, 23305, 23389, 23466, 23565, 23600, 23724, 23743, 23817, 23818, 23819, 23999, 24167, 24196, 24201, 24214, 24240, 24246, 24308, 24375, 24452, 24567, 24571, 24579, 24613, 24625, 24628, 24643, 24646, 24742, 24857, 24867, 24975, 25215, 25219, 25276, 25277, 25416, 25421, 25427, 25446, 25519, 25671, 25689, 25746, 25751, 25765, 25806, 25848, 25958, 25965, 26016, 26179, 26338, 26352, 26397, 26497, 26607, 26712, 26713, 26714, 26717, 26736, 26820, 26839, 26844, 27067, 27126, 27156, 27189, 27202, 27213, 27224, 27229, 27264, 27302, 27347, 27390, 27406, 27422, 27521, 27613, 27718, 27825, 27837, 27846, 27917, 27969, 28013, 28067, 28085, 28103, 28135, 28152, 28157, 28250, 28316, 28410, 28567, 28581, 28619, 28645, 28651, 28798, 28853, 28922, 29054, 29088, 29105, 29181, 29269, 29327, 29361, 29428, 29514, 29527, 29547, 29578, 29629, 29630, 29759, 29835, 29880, 29961, 29979, 30005, 30025, 30279, 30316, 30407, 30443, 30762, 30778, 30883, 31042, 31046, 31136, 31138, 31165, 31312, 31413, 31457, 31464, 31530, 31561, 31585, 31617, 31748, 31773, 31818, 31835, 31845, 31853, 31882, 31901, 31951, 32042, 32253, 32306, 32321, 32354, 32387, 32510, 32540, 32648, 32722, 32788, 32807, 32868, 32892, 32958, 32968, 32985, 33037, 33042, 33172, 33263, 33309, 33366, 33374, 33380, 33394, 33427, 33491, 33528, 33570, 33601, 33819, 33829, 33863, 33926, 33954, 34053, 34106, 34312, 34366, 34429, 34628, 34633, 34823, 34884, 35075, 35094, 35115, 35206, 35246, 35273, 35300, 35490, 35525, 35535, 35647, 35649, 35671, 35780, 35870, 35931, 36083, 36171, 36177, 36201, 36216, 36289, 36329, 36335, 36402, 36453, 36534, 36705, 36815, 36822, 36842, 36889, 36902, 36944, 36961, 37108, 37121, 37297, 37304, 37462, 37500, 37596, 37607, 37697, 37710, 37781, 37900, 38027, 38046, 38052, 38062, 38365, 38415, 38440, 38485, 38533, 38548, 38757, 38879, 38890, 39111, 39232, 39270, 39316, 39410, 39459, 39523, 39537, 39660, 39832, 40008, 40053, 40152, 40254, 40283, 40323, 40398, 40488, 40502, 40520, 40547, 40586, 40601, 40685, 40702, 40774, 40828, 40867, 40950, 40976, 40990, 41012, 41045, 41058, 41143, 41201, 41290, 41305, 41306, 41318, 41350, 41458, 41459, 41474, 41485, 41609, 41652, 41663, 41784, 41876, 41906, 41927, 42201, 42252, 42301, 42358, 42375, 42504, 42546, 42552, 42587, 42661, 42662, 42666, 42668, 42734, 42791, 42808, 42814, 42865, 42869, 42882, 42950, 42952, 42976, 43004, 43022, 43050, 43180, 43194, 43219, 43357, 43466, 43471, 43503, 43678, 43681, 43773, 43792, 43856, 43882, 43979, 43994, 44174, 44208, 44270, 44311, 44361, 44416, 44449, 44459, 44461, 44462, 44466, 44470, 44473, 44503, 44514, 44565, 44572, 44714, 44730, 44788, 44868, 44919, 44941, 45004, 45029, 45033, 45045, 45115, 45144, 45155, 45218, 45366, 45367, 45505, 45541, 45602, 45619, 45697, 45776, 45831, 45833, 45835, 45893, 45915, 45992, 46102, 46227, 46334, 46383, 46412, 46465, 46487, 46494, 46507, 46608, 46671, 46763, 46804, 46834, 46981, 46984, 47071, 47171, 47187, 47218, 47232, 47346, 47416, 47443, 47454, 47494, 47581, 47666, 47704, 47838, 47907, 47941, 47944, 47968, 48063, 48119, 48182, 48193, 48199, 48280, 48345, 48346, 48389, 48480, 48567, 48643, 48697, 48708, 48709, 48736, 48800, 48878, 48889, 48935, 48963, 49039, 49050, 49160, 49203, 49222, 49249, 49273, 49281, 49302, 49330, 49355, 49478, 49517, 49542, 49544, 49600, 49615, 49704, 49713, 49831, 49845, 49947, 49988, 50030, 50147, 50271, 50391, 50405, 50499, 50585, 50610, 50623, 50658, 50729, 50761, 50870, 51001, 51231, 51288, 51327, 51361, 51390, 51416, 51458, 51493, 51509, 51535, 51549, 51606, 51639, 51735, 51774, 51801, 51810, 51819, 51935, 52010, 52081, 52145, 52154, 52178, 52206, 52220, 52383, 52478, 52489, 52536, 52677, 52681, 52845, 52873, 52880, 52896, 53081, 53189, 53222, 53300, 53389, 53422, 53480, 53500, 53568, 53598, 53676, 53862, 53897, 53901, 53951, 54019, 54056, 54151, 54385, 54394, 54418, 54535, 54676, 54683, 54813, 54844, 55036, 55301, 55337, 55506, 55516, 55538, 55546, 55583, 55629, 55735, 55756, 55795, 55859, 55998, 56003, 56011, 56094, 56214, 56282, 56430, 56469, 56524, 56528, 56535, 56595, 56723, 56807, 56837, 56876, 56981, 57017, 57051, 57275, 57384, 57474, 57689, 57776, 57843, 57940, 58025, 58063, 58112, 58289, 58395, 58531, 58550, 58558, 58573, 58622, 58781, 58786, 58950, 58959, 59104, 59122, 59138, 59230, 59263, 59568, 59651, 59666, 59669, 59888, 60019, 60056, 60079, 60111, 60119, 60141, 60157, 60252, 60651, 60664, 60676, 60713, 60844, 61017, 61104, 61164, 61302, 61320, 61359, 61465, 61504, 61569, 61592, 61912, 61961, 61986, 62001, 62028, 62240, 62320, 62404, 62435, 62497, 62507, 62739, 62768, 62870, 62924, 63131, 63140, 63185, 63208, 63227, 63379, 63383, 63393, 63548, 63587, 63693, 63716, 63724, 63749, 63753, 63772, 63847, 63864, 63896, 63944, 63951, 64046, 64097, 64100, 64180, 64186, 64188, 64260, 64329, 64365, 64408, 64471, 64602, 64683, 64692, 64833, 65024, 65146, 65174, 65179, 65294, 65313, 65403, 65412, 65419, 65432, 65438, 65470, 65534, 65596, 65675, 65787, 65871, 65924, 65928, 65938, 65961, 66005, 66027, 66029, 66033, 66046, 66050, 66093, 66096, 66116, 66157, 66197, 66367, 66368, 66463, 66496, 66525, 66577, 66631, 66660, 66699, 66921, 66939, 66956, 66974, 67005, 67019, 67084, 67118, 67154, 67282, 67291, 67334, 67336, 67353, 67386, 67509, 67510, 67512, 67522, 67585, 67627, 67684, 67725, 67735, 67744, 67786, 67849, 67850, 67889, 67943, 68038, 68151, 68158, 68314, 68354, 68379, 68453, 68489, 68610, 68880, 68906, 69007, 69052, 69067, 69132, 69223, 69238, 69345, 69429, 69487, 69491, 69557, 69619, 69713, 69728, 69892, 69926, 69928, 70094, 70118, 70129, 70173, 70353, 70520, 70649, 70688, 70816, 70936, 70969, 70970, 70977, 70980, 70989, 71009, 71091, 71158, 71232, 71244, 71285, 71288, 71387, 71535, 71588, 71625, 71863, 72032, 72221, 72225, 72311, 72321, 72333, 72576, 72668, 72729, 72754, 72847, 72884, 72915, 72936, 72942, 73013, 73047, 73153, 73185, 73220, 73249, 73291, 73408, 73508, 73538, 73582, 73596, 73599, 73616, 73739, 73770, 73781, 74008, 74078, 74168, 74264, 74377, 74496, 74517, 74572, 74577, 74628, 74646, 74704, 74710, 74720, 74732, 74740, 74860, 74994, 75034, 75040, 75071, 75119, 75163, 75195, 75311, 75376, 75378, 75511, 75544, 75600, 75781, 75822, 75870, 75927, 75929, 75941, 76232, 76295, 76310, 76354, 76376, 76422, 76564, 76882, 76903, 77065, 77130, 77147, 77157, 77202, 77248, 77309, 77342, 77410, 77532, 77546, 77560, 77632, 77658, 77749, 77785, 77922, 77958, 78088, 78103, 78104, 78203, 78213, 78251, 78273, 78287, 78311, 78514, 78578, 78689, 78698, 78775, 78843, 79048, 79082, 79108, 79130, 79142, 79274, 79282, 79457, 79482, 79519, 79597, 79646, 79797, 79805, 79824, 79883, 79893, 79921, 80077, 80080, 80111, 80122, 80125, 80181, 80233, 80244, 80258, 80277, 80287, 80291, 80312, 80319, 80470, 80554, 80558, 80563, 80610, 80669, 80703, 80975, 80995, 81026, 81103, 81104, 81160, 81221, 81256, 81262, 81341, 81354, 81361, 81387, 81397, 81436, 81461, 81470, 81478, 81542, 81547, 81571, 81634, 81641, 81655, 81701, 81713, 81720, 81933, 81970, 81977, 81999, 82097, 82099, 82105, 82231, 82291, 82376, 82391, 82448, 82548, 82560, 82754, 82869, 82974, 82987, 83019, 83060, 83080, 83131, 83132, 83215, 83229, 83436, 83467, 83474, 83590, 83649, 83681, 83701, 83759, 83771, 83960, 84107, 84162, 84174, 84215, 84220, 84254, 84287, 84297, 84375, 84449, 84454, 84456, 84465, 84470, 84618, 84670, 84680, 84793, 84871, 84981, 85061, 85081, 85132, 85138, 85177, 85275, 85389, 85391, 85435, 85439, 85558, 85716, 85722, 85745, 85900, 85908, 85972, 86062, 86127, 86290, 86381, 86418, 86485, 86504, 86565, 86589, 86622, 86645, 86694, 86746, 86764, 86786, 86888, 87013, 87029, 87071, 87118, 87153, 87163, 87237, 87354, 87405, 87567, 87753, 87755, 87770, 87782, 87783, 87835, 87856, 87877, 87939, 87965, 87982, 88016, 88139, 88179, 88232, 88381, 88435, 88448, 88479, 88658, 88710, 88718, 88888, 88980, 89006, 89123, 89132, 89150, 89204, 89211, 89288, 89445, 89474, 89573, 89671, 89708, 89849, 89884, 90115, 90139, 90299, 90376, 90383, 90540, 90557, 90605, 90623, 90646, 90668, 90732, 90744, 90765, 90772, 90828, 90872, 90921, 90943, 91309, 91371, 91492, 91496, 91515, 91581, 91651, 91807, 91886, 91948, 92101, 92116, 92117, 92151, 92191, 92233, 92238, 92248, 92290, 92364, 92572, 92669, 92676, 92700, 92812, 92864, 92911, 92950, 92988, 93105, 93260, 93340, 93380, 93427, 93594, 93607, 93689, 93787, 93874, 93914, 93939, 93964, 94080, 94182, 94333, 94427, 94490, 94567, 94625, 94755, 94804, 94819, 94899, 94930, 94982, 94995, 95010, 95011, 95015, 95093, 95254, 95273, 95331, 95382, 95475, 95537, 95542, 95602, 95643, 95666, 95748, 95756, 95883, 95933, 95953, 96036, 96044, 96072, 96108, 96136, 96149, 96217, 96243, 96274, 96284, 96293, 96308, 96338, 96493, 96497, 96571, 96576, 96593, 96659, 96732, 96738, 96810, 96824, 96871, 96898, 96909, 96943, 96992, 97006, 97029, 97035, 97052, 97056, 97110, 97153, 97219, 97230, 97237, 97407, 97504, 97529, 97549, 97571, 97588, 97713, 97745, 97800, 97897, 97918, 97985, 98005, 98198, 98229, 98232, 98249, 98328, 98349, 98511, 98719, 98811, 98822, 98872, 98903, 98931, 98933, 99043, 99068, 99151, 99165, 99204, 99300, 99324, 99328, 99355, 99416, 99452, 99464, 99468, 99476, 99504, 99543, 99741, 99775, 99796, 99915, 99926, 99995]\n",
      "num_sample : 98324\n",
      "mask_mat: (98324, 1, 1, 60)\n",
      "mol_atom_feat.shape: (98324, 60, 71)\n",
      "distance value type is: exp\n",
      "all_adj.shape = : (98324, 60, 60)\n",
      "all_dist.shape = : (98324, 60, 60)\n",
      "od_shuffled.shape =  (98324, 12)\n"
     ]
    }
   ],
   "source": [
    "test = Haha.Transformer2Sub()\n",
    "test.molData_atomicF(smiles_list, dist_value='exp', atomH=False, failed_mol=None, rseed=0)\n",
    "test.odData2(smiles_list, sub_dict, od_name=od_name_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combination of substructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dict['12'] = '6 and 10'\n",
    "sub_dict['13'] = '6 and 8'\n",
    "sub_dict['14'] = '2 and 8'\n",
    "sub_dict['15'] = '1 or 7'\n",
    "sub_dict['16'] = '0 or 1'\n",
    "sub_dict['17'] = '11 or 3'\n",
    "sub_dict['18'] = '6 and 8 and 9'\n",
    "sub_dict['19'] = '2 and 5 and 10'\n",
    "sub_dict['20'] = '0 or 1 or 7'\n",
    "sub_dict['21'] = '3 or 4 or 11'\n",
    "sub_dict['22'] = '(6 and 9) or 8'\n",
    "sub_dict['23'] = '(2 and 8) or 0'\n",
    "\n",
    "\n",
    "def addSub(od_mat, target_atom=None):\n",
    "    # target_atom.shape = (samples, sub_basic, max_mol)\n",
    "    samples = od_mat.shape[0]\n",
    "\n",
    "    add_od_mat = []\n",
    "    if target_atom is not None:\n",
    "        add_target_atom = []\n",
    "        max_mol = target_atom.shape[-1]\n",
    "\n",
    "    def sub1_and_sub2(sub1, sub2):\n",
    "        temp = od_mat[:, sub1] + od_mat[:, sub2] # 0,1,2\n",
    "        temp -= 1 # -1,0,1\n",
    "        temp = tf.clip_by_value(temp, clip_value_min=0, clip_value_max=1) # 0,1 shape=(samples, )\n",
    "        temp = tf.expand_dims(temp, axis=1) # shape=(samples, 1)\n",
    "\n",
    "        temp_tar = None\n",
    "        if target_atom is not None:\n",
    "            temp_tar = target_atom[:, sub1, :] + target_atom[:, sub2, :] # (samples, max_mol)\n",
    "            temp_tar *= temp\n",
    "            temp_tar = tf.expand_dims(temp_tar, axis=1) # shape=(samples, 1, max_mol)    \n",
    "\n",
    "        return (temp, temp_tar)    \n",
    "\n",
    "    def sub1_or_sub2(sub1, sub2):\n",
    "        temp = od_mat[:, sub1] + od_mat[:, sub2] # 0,1,2\n",
    "        temp = tf.clip_by_value(temp, clip_value_min=0, clip_value_max=1) # 0,1 shape=(samples, )\n",
    "        temp = tf.expand_dims(temp, axis=1) # shape=(samples, 1)\n",
    "\n",
    "        temp_tar = None\n",
    "        if target_atom is not None:\n",
    "            temp_tar = target_atom[:, sub1, :] + target_atom[:, sub2, :] # (samples, max_mol)\n",
    "            temp_tar = tf.expand_dims(temp_tar, axis=1) # shape=(samples, 1, max_mol)    \n",
    "\n",
    "        return (temp, temp_tar)  \n",
    "\n",
    "    def sub1_and_sub2_and_sub3(sub1, sub2, sub3):\n",
    "        temp = od_mat[:, sub1] + od_mat[:, sub2] + od_mat[:, sub3]# 0,1,2,3\n",
    "        temp -= 2 # -2,-1,0,1\n",
    "        temp = tf.clip_by_value(temp, clip_value_min=0, clip_value_max=1) # 0,1 shape=(samples, )\n",
    "        temp = tf.expand_dims(temp, axis=1) # shape=(samples, 1)\n",
    "\n",
    "        temp_tar = None\n",
    "        if target_atom is not None:\n",
    "            temp_tar = target_atom[:, sub1, :] + target_atom[:, sub2, :] + target_atom[:, sub3, :] # (samples, max_mol)\n",
    "            temp_tar *= temp\n",
    "            temp_tar = tf.expand_dims(temp_tar, axis=1) # shape=(samples, 1, max_mol)    \n",
    "\n",
    "        return (temp, temp_tar)    \n",
    "\n",
    "    def sub1_or_sub2_or_sub3(sub1, sub2, sub3):\n",
    "        temp = od_mat[:, sub1] + od_mat[:, sub2] + od_mat[:, sub3] # 0,1,2,3\n",
    "        temp = tf.clip_by_value(temp, clip_value_min=0, clip_value_max=1) # 0,1 shape=(samples, )\n",
    "        temp = tf.expand_dims(temp, axis=1) # shape=(samples, 1)\n",
    "\n",
    "        temp_tar = None\n",
    "        if target_atom is not None:\n",
    "            temp_tar = target_atom[:, sub1, :] + target_atom[:, sub2, :] + target_atom[:, sub3, :]# (samples, max_mol)\n",
    "            temp_tar = tf.expand_dims(temp_tar, axis=1) # shape=(samples, 1, max_mol)    \n",
    "\n",
    "        return (temp, temp_tar)   \n",
    "\n",
    "    def sub1_and_sub2_or_sub3(sub1, sub2, sub3):\n",
    "        # (sub1 and sub2) or sub3\n",
    "        temp_and = od_mat[:, sub1] + od_mat[:, sub2] # 0,1,2\n",
    "        temp_and -= 1\n",
    "        temp_and = tf.clip_by_value(temp_and, clip_value_min=0, clip_value_max=1) # 0,1 shape=(samples, )\n",
    "        temp = temp_and + od_mat[:, sub3]\n",
    "        temp = tf.clip_by_value(temp, clip_value_min=0, clip_value_max=1) # 0,1 shape=(samples, )\n",
    "        temp = tf.expand_dims(temp, axis=1) # shape=(samples, 1)\n",
    "\n",
    "        temp_tar = None\n",
    "        if target_atom is not None:\n",
    "            temp_and = tf.expand_dims(temp_and, axis=1) # (samples, 1)\n",
    "            temp_tar = temp_and*(target_atom[:, sub1, :] + target_atom[:, sub2, :]) + od_mat[:, sub3:sub3+1]*target_atom[:, sub3, :]# (samples, max_mol)\n",
    "            temp_tar = tf.expand_dims(temp_tar, axis=1) # shape=(samples, 1, max_mol)  \n",
    "\n",
    "        return(temp, temp_tar)\n",
    "\n",
    "\n",
    "    ###### sub1 and sub2 #######\n",
    "    # 6 and 10\n",
    "    temp, temp_tar = sub1_and_sub2(6, 10)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "    # 6 and 8\n",
    "    temp, temp_tar = sub1_and_sub2(6, 8)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "    # 2 and 8\n",
    "    temp, temp_tar = sub1_and_sub2(2, 8)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "\n",
    "    ###### sub1 or sub2 #######\n",
    "    # 1 or 7\n",
    "    temp, temp_tar = sub1_or_sub2(1, 7)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "    # 0 or 1\n",
    "    temp, temp_tar = sub1_or_sub2(0, 1)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "    # 11 or 3\n",
    "    temp, temp_tar = sub1_or_sub2(11, 3)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "\n",
    "    ###### sub1 and sub2 and sub3 ######\n",
    "    # 6 and 8 and 9\n",
    "    temp, temp_tar = sub1_and_sub2_and_sub3(6, 8, 9)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "    # 2 and 5 and 10\n",
    "    temp, temp_tar = sub1_and_sub2_and_sub3(2, 5, 10)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "\n",
    "    ###### sub1 or sub2 or sub3 ######\n",
    "    # 0 or 1 or 7\n",
    "    temp, temp_tar = sub1_or_sub2_or_sub3(0, 1, 7)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "    # 3 or 4 or 11\n",
    "    temp, temp_tar = sub1_or_sub2_or_sub3(3, 4, 11)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "\n",
    "    ###### (sub1 and sub2) or sub3 ######\n",
    "    # (6 and 9) or 8\n",
    "    temp, temp_tar = sub1_and_sub2_or_sub3(6, 9, 8)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "    # (2 and 8) or 0\n",
    "    temp, temp_tar = sub1_and_sub2_or_sub3(2, 8, 0)\n",
    "    add_od_mat.append(temp)\n",
    "    if target_atom is not None:\n",
    "        add_target_atom.append(temp_tar)\n",
    "\n",
    "    ###########################################################\n",
    "    # 把add_od_mat, add_target_atom合到一起\n",
    "    add_od_mat = tf.concat(add_od_mat, axis=1) \n",
    "    if target_atom is not None:\n",
    "        add_target_atom = tf.concat(add_target_atom, axis=1)\n",
    "        add_target_atom = tf.clip_by_value(add_target_atom, clip_value_min=0, clip_value_max=1)\n",
    "\n",
    "        return (add_od_mat, add_target_atom)\n",
    "    \n",
    "    else:\n",
    "        return(add_od_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make full outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81935, 24)\n",
      "(16389, 24, 60)\n",
      "positive sample distribution in train set:\n",
      "{'0': 5646.0, '1': 4531.0, '2': 21496.0, '3': 408.0, '4': 184.0, '5': 19257.0, '6': 49538.0, '7': 1897.0, '8': 18533.0, '9': 41583.0, '10': 48701.0, '11': 116.0, '12': 29677.0, '13': 10678.0, '14': 6920.0, '15': 6124.0, '16': 10048.0, '17': 524.0, '18': 5296.0, '19': 8475.0, '20': 11549.0, '21': 705.0, '22': 39219.0, '23': 12217.0}\n",
      "positive sample distribution in test set:\n",
      "{'0': 1110.0, '1': 913.0, '2': 4325.0, '3': 73.0, '4': 39.0, '5': 3850.0, '6': 9836.0, '7': 354.0, '8': 3757.0, '9': 8238.0, '10': 9717.0, '11': 27.0, '12': 5850.0, '13': 2144.0, '14': 1407.0, '15': 1209.0, '16': 2002.0, '17': 100.0, '18': 1039.0, '19': 1721.0, '20': 2280.0, '21': 139.0, '22': 7868.0, '23': 2453.0}\n",
      "positive sample distribution in all data:\n",
      "{'0': 6756.0, '1': 5444.0, '2': 25821.0, '3': 481.0, '4': 223.0, '5': 23107.0, '6': 59374.0, '7': 2251.0, '8': 22290.0, '9': 49821.0, '10': 58418.0, '11': 143.0, '12': 35527.0, '13': 12822.0, '14': 8327.0, '15': 7333.0, '16': 12050.0, '17': 624.0, '18': 6335.0, '19': 10196.0, '20': 13829.0, '21': 844.0, '22': 47087.0, '23': 14670.0}\n"
     ]
    }
   ],
   "source": [
    "test.feature_od = len(sub_dict)\n",
    "\n",
    "test.od_name = []\n",
    "for i in sub_dict:\n",
    "    test.od_name.append(i)\n",
    "\n",
    "add_od_mat = addSub(test.od_train, target_atom=None)\n",
    "test.od_train = tf.concat([test.od_train, add_od_mat], axis=1)\n",
    "print(test.od_train.shape)\n",
    "\n",
    "add_od_mat, add_target_atom = addSub(test.od_test, target_atom=test.target_atoms)\n",
    "test.od_test = tf.concat([test.od_test, add_od_mat], axis=1)\n",
    "print(test.od_train.shape)\n",
    "test.target_atoms = tf.concat([test.target_atoms, add_target_atom], axis=1)\n",
    "print(test.target_atoms.shape)\n",
    "\n",
    "\n",
    "positive = tf.reduce_sum(test.od_train, axis=0)\n",
    "positive_dict = {}\n",
    "for each in range(test.feature_od):\n",
    "    positive_dict[test.od_name[each]] = positive[each].numpy()\n",
    "print('positive sample distribution in train set:')\n",
    "print(positive_dict)\n",
    "\n",
    "positive = tf.reduce_sum(test.od_test, axis=0)\n",
    "positive_dict1 = {}\n",
    "for each in range(test.feature_od):\n",
    "    positive_dict1[test.od_name[each]] = positive[each].numpy()\n",
    "print('positive sample distribution in test set:')\n",
    "print(positive_dict1)\n",
    "\n",
    "total_pos_dict = {}\n",
    "for each in positive_dict:\n",
    "    total_pos_dict[each] = positive_dict[each] + positive_dict1[each]\n",
    "print('positive sample distribution in all data:')\n",
    "print(total_pos_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.use_adj_dist = 'both'\n",
    "\n",
    "hpara = {\n",
    "            'num_heads': 12,\n",
    "            'single_attn_dim': 15,\n",
    "            'num_encoderLayer': 6,\n",
    "            'num_decoderLayer': 1, \n",
    "            'learning_rate': 0.00007, \n",
    "            'temperature': 0.7\n",
    "        }\n",
    "\n",
    "record_dir='/tf/haha/code/logs/1114/sub-12_15_61'\n",
    "\n",
    "weight_path = '/tf/haha/save_weight/1114/sub-12_15_61/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/haha/code/logs/1114/sub-12_15_61\n",
      "modelBuild2-temperature 0.700000\n",
      "(81935, 1, 1)\n",
      "(81935, 60, 71)\n",
      "(81935, 60, 60)\n",
      "(81935, 60, 60)\n",
      "(81935, 1, 1, 60)\n",
      "(81935, 24)\n",
      "0 WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (15, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (15, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (15, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (15, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\"), but it was called on an input with incompatible shape (15, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 24) for input KerasTensor(type_spec=TensorSpec(shape=(32, 24), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\"), but it was called on an input with incompatible shape (15, 24).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (5, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 71) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 71), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (5, 60, 71).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (5, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 60, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 60, 60), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (5, 60, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 1, 1, 60) for input KerasTensor(type_spec=TensorSpec(shape=(32, 1, 1, 60), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\"), but it was called on an input with incompatible shape (5, 1, 1, 60).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 24) for input KerasTensor(type_spec=TensorSpec(shape=(32, 24), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\"), but it was called on an input with incompatible shape (5, 24).\n",
      "1 2 3 4 5 6 7 8 9 10 weight保存开始：Mon Nov 14 10:11:23 2022 weight保存完成 Mon Nov 14 10:11:23 2022\n",
      "11 weight保存开始：Mon Nov 14 10:15:03 2022 weight保存完成 Mon Nov 14 10:15:03 2022\n",
      "12 weight保存开始：Mon Nov 14 10:18:43 2022 weight保存完成 Mon Nov 14 10:18:44 2022\n",
      "13 14 weight保存开始：Mon Nov 14 10:26:03 2022 weight保存完成 Mon Nov 14 10:26:04 2022\n",
      "15 weight保存开始：Mon Nov 14 10:29:44 2022 weight保存完成 Mon Nov 14 10:29:44 2022\n",
      "16 weight保存开始：Mon Nov 14 10:33:25 2022 weight保存完成 Mon Nov 14 10:33:25 2022\n",
      "17 weight保存开始：Mon Nov 14 10:37:05 2022 weight保存完成 Mon Nov 14 10:37:06 2022\n",
      "18 weight保存开始：Mon Nov 14 10:40:46 2022 weight保存完成 Mon Nov 14 10:40:46 2022\n",
      "19 weight保存开始：Mon Nov 14 10:44:26 2022 weight保存完成 Mon Nov 14 10:44:26 2022\n",
      "20 weight保存开始：Mon Nov 14 10:48:06 2022 weight保存完成 Mon Nov 14 10:48:07 2022\n",
      "21 22 23 weight保存开始：Mon Nov 14 10:59:08 2022 weight保存完成 Mon Nov 14 10:59:08 2022\n",
      "24 weight保存开始：Mon Nov 14 11:02:48 2022 weight保存完成 Mon Nov 14 11:02:48 2022\n",
      "25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 weight保存开始：Mon Nov 14 12:01:31 2022 weight保存完成 Mon Nov 14 12:01:31 2022\n",
      "41 42 43 44 45 46 47 48 49 50 51 52 53 54 weight保存开始：Mon Nov 14 12:53:02 2022 weight保存完成 Mon Nov 14 12:53:02 2022\n",
      "55 56 57 58 59 60 weight保存开始：Mon Nov 14 13:15:08 2022 weight保存完成 Mon Nov 14 13:15:10 2022\n",
      "61 62 63 weight保存开始：Mon Nov 14 13:26:12 2022 weight保存完成 Mon Nov 14 13:26:12 2022\n",
      "64 65 weight保存开始：Mon Nov 14 13:33:34 2022 weight保存完成 Mon Nov 14 13:33:34 2022\n",
      "66 67 weight保存开始：Mon Nov 14 13:40:56 2022 weight保存完成 Mon Nov 14 13:40:56 2022\n",
      "68 69 70 71 72 weight保存开始：Mon Nov 14 13:59:20 2022 weight保存完成 Mon Nov 14 13:59:21 2022\n",
      "73 74 75 weight保存开始：Mon Nov 14 14:10:23 2022 weight保存完成 Mon Nov 14 14:10:23 2022\n",
      "76 77 78 79 80 weight保存开始：Mon Nov 14 14:28:48 2022 weight保存完成 Mon Nov 14 14:28:49 2022\n",
      "81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 weight保存开始：Mon Nov 14 16:19:07 2022 weight保存完成 Mon Nov 14 16:19:07 2022\n",
      "111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 weight保存开始：Mon Nov 14 18:20:28 2022 weight保存完成 Mon Nov 14 18:20:29 2022\n",
      "144 weight保存开始：Mon Nov 14 18:24:09 2022 weight保存完成 Mon Nov 14 18:24:09 2022\n",
      "145 146 147 weight保存开始：Mon Nov 14 18:35:12 2022 weight保存完成 Mon Nov 14 18:35:12 2022\n",
      "148 149 weight保存开始：Mon Nov 14 18:42:33 2022 weight保存完成 Mon Nov 14 18:42:33 2022\n",
      "150 151 152 weight保存开始：Mon Nov 14 18:53:34 2022 weight保存完成 Mon Nov 14 18:53:35 2022\n",
      "153 154 155 156 157 weight保存开始：Mon Nov 14 19:11:59 2022 weight保存完成 Mon Nov 14 19:11:59 2022\n",
      "158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 weight保存开始：Mon Nov 14 21:02:22 2022 weight保存完成 Mon Nov 14 21:02:22 2022\n",
      "188 189 190 191 192 193 194 195 196 197 198 199 weight保存开始：Mon Nov 14 21:46:32 2022 weight保存完成 Mon Nov 14 21:46:32 2022\n",
      "{'avg': 0.9852966397254473, 'avg_pcs': 0.9864572410782179, 'avg_rc': 0.9842843388517698, '0': 0.9986480532489226, '1': 1.0, '2': 0.9998844132350244, '3': 0.9241379519620208, '4': 0.9473684311036918, '5': 1.0, '6': 0.9959382826187027, '7': 0.9700427955833555, '8': 1.0, '9': 1.0, '10': 1.0, '11': 0.981132086930049, '12': 0.9971792625051548, '13': 0.9941819804831352, '14': 1.0, '15': 0.9946125360040785, '16': 0.9992505880468877, '17': 0.9162561587231598, '18': 0.997115375584063, '19': 0.9997095516372204, '20': 0.9969244205309656, '21': 0.9366197369222696, '22': 0.9987293432926738, '23': 0.9993883849993581}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x7f239f14d190>,\n",
       " {'avg': 0.9852966397254473,\n",
       "  'avg_pcs': 0.9864572410782179,\n",
       "  'avg_rc': 0.9842843388517698,\n",
       "  '0': 0.9986480532489226,\n",
       "  '1': 1.0,\n",
       "  '2': 0.9998844132350244,\n",
       "  '3': 0.9241379519620208,\n",
       "  '4': 0.9473684311036918,\n",
       "  '5': 1.0,\n",
       "  '6': 0.9959382826187027,\n",
       "  '7': 0.9700427955833555,\n",
       "  '8': 1.0,\n",
       "  '9': 1.0,\n",
       "  '10': 1.0,\n",
       "  '11': 0.981132086930049,\n",
       "  '12': 0.9971792625051548,\n",
       "  '13': 0.9941819804831352,\n",
       "  '14': 1.0,\n",
       "  '15': 0.9946125360040785,\n",
       "  '16': 0.9992505880468877,\n",
       "  '17': 0.9162561587231598,\n",
       "  '18': 0.997115375584063,\n",
       "  '19': 0.9997095516372204,\n",
       "  '20': 0.9969244205309656,\n",
       "  '21': 0.9366197369222696,\n",
       "  '22': 0.9987293432926738,\n",
       "  '23': 0.9993883849993581})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.modelTrain2(hpara, epochs=200, batch_size=32, record_dir=record_dir, save_threshold=0.9, save_path=weight_path, normal_init=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output\n",
    "out_train = []\n",
    "out_test = []\n",
    "for i in range(test.feature_od):\n",
    "    out_train.append(test.od_train[:, i])\n",
    "    out_test.append(test.od_test[:, i])\n",
    "out_train = tuple(out_train)\n",
    "out_test = tuple(out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "test.use_adj_dist = 'both'\n",
    "model = test.modelBuild2(batch_size=32, num_heads=8, single_attn_dim=30, feedforward_dim=240, num_encoderLayer=7, \n",
    "                    num_decoderLayer=2, dropout_rate=0.1, lr=0.00002, compile=True, normal_init=False, temperature=0.7)\n",
    "\n",
    "model.load_weights('/tf/haha/save_weight/1114/od98-8_30_72/')\n",
    "\n",
    "if len(test.test_input) == test.input_items-1:\n",
    "    test.test_input = list(test.test_input)\n",
    "    test.test_input.append(test.od_test)\n",
    "    test.test_input = tuple(test.test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(test.test_input)\n",
    "\n",
    "# F1 \n",
    "metrics_dict = {\n",
    "            'precision': [],\n",
    "            'recall': []\n",
    "        }\n",
    "\n",
    "for each in range(test.feature_od):\n",
    "    metrics_dict['precision'].append(\n",
    "        tf.keras.metrics.Precision(name=test.od_name[each]+'_precision'))\n",
    "    metrics_dict['recall'].append(\n",
    "        tf.keras.metrics.Recall(name=test.od_name[each]+'_recall'))\n",
    "\n",
    "evaluate_dict = {}\n",
    "for i in range(test.feature_od):\n",
    "    metrics_dict['precision'][i].update_state(\n",
    "        out_test[i], preds[i])\n",
    "    metrics_dict['recall'][i].update_state(\n",
    "        out_test[i], preds[i])\n",
    "\n",
    "    od = test.od_name[i]\n",
    "    pcs = metrics_dict['precision'][i].result()\n",
    "    evaluate_dict[od+'_'+od+'_'+'precision'] = float(pcs)\n",
    "    rc = metrics_dict['recall'][i].result()\n",
    "    evaluate_dict[od+'_'+od+'_'+'recall'] = float(rc)\n",
    "\n",
    "fscore_dict = test.calFscore(evaluate_dict)\n",
    "print(fscore_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attnDraw (Figure9)\n",
    "selected_od = ['fruity', 'sweet', 'green'] # ...\n",
    "\n",
    "attn = preds[-2]\n",
    "attn = [attn[-1]] # if draw each dc layer, delete this line\n",
    "savepath = '/tf/haha/img_result/1114/od98-8_30_72/'\n",
    "test.drawAttn(attn, smiles_list, preds, savepath, max_draw=50, addH=False,\n",
    "                per_head=False, trainORtest='test', attn_c=0.5, posneg='positive', selected_od=selected_od)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
